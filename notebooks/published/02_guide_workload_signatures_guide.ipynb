{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aed1bbd",
   "metadata": {},
   "source": [
    "# Understanding Cloud Workload Signatures: A Comprehensive Guide 2\n",
    "\n",
    "This notebook explores **why** different cloud workload types have distinct resource utilization patterns. We'll examine the underlying technical and business reasons that create these signatures, grounded in empirical research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "# Local: Uses installed hellocloud\n",
    "# Colab: Installs from GitHub\n",
    "try:\n",
    "    import hellocloud\n",
    "except ImportError:\n",
    "    !pip install -q git+https://github.com/nehalecky/hello-cloud.git\n",
    "    import hellocloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9cb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload: Picks up library changes without kernel restart\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46322a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars replaced with PySpark\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List\n",
    "\n",
    "# Configure Altair for interactive visualizations\n",
    "alt.data_transformers.enable('default')  # Use default transformer for now\n",
    "alt.theme.enable('quartz')  # Clean, professional theme\n",
    "\n",
    "# Import our simulation framework\n",
    "from hellocloud.generation import WorkloadPatternGenerator, WorkloadType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d4c5c",
   "metadata": {},
   "source": [
    "## Part 1: Foundations - Why Do Workload Signatures Exist?\n",
    "\n",
    "Before diving into specific patterns, let's understand the fundamental forces that create distinct workload signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973de08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conceptual diagram showing the forces that shape workload signatures\n",
    "forces_data = spark.createDataFrame({\n",
    "    'category': ['Hardware', 'Hardware', 'Architecture', 'Architecture',\n",
    "                 'Business', 'Business', 'Optimization', 'Optimization'],\n",
    "    'factor': ['CPU-Memory Bus', 'I/O Latency', 'Request Model', 'State Management',\n",
    "               'User Behavior', 'Business Hours', 'Auto-scaling', 'Caching'],\n",
    "    'impact_level': [7, 8, 9, 8, 10, 9, 6, 7],\n",
    "    'description': [\n",
    "        'Physical constraints on data movement',\n",
    "        'Storage and network access delays',\n",
    "        'Sync vs async, batch vs stream',\n",
    "        'Stateful vs stateless design',\n",
    "        'Human activity patterns',\n",
    "        'Work schedules and timezones',\n",
    "        'Dynamic resource adjustment',\n",
    "        'Memory-speed tradeoffs'\n",
    "    ]\n",
    "})\n",
    "\n",
    "forces_chart = alt.Chart(forces_data.toPandas()).mark_bar().encode(\n",
    "    x=alt.X('impact_level:Q', title='Impact on Signature', scale=alt.Scale(domain=[0, 10])),\n",
    "    y=alt.Y('factor:N', title='Contributing Factor', sort='-x'),\n",
    "    color=alt.Color('category:N', title='Category', scale=alt.Scale(scheme='tableau10')),\n",
    "    tooltip=['factor', 'description', 'impact_level']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Forces That Shape Workload Signatures'\n",
    ").interactive()\n",
    "\n",
    "forces_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae46469",
   "metadata": {},
   "source": [
    "### The Physics of Computing\n",
    "\n",
    "Resource utilization patterns emerge from fundamental computing constraints:\n",
    "\n",
    "1. **CPU-Memory Bandwidth**: Data must move between CPU and memory, creating correlations\n",
    "2. **I/O Wait States**: CPUs idle while waiting for disk/network operations\n",
    "3. **Cache Hierarchies**: L1/L2/L3 caches create step functions in performance\n",
    "4. **Thermal Limits**: Sustained high utilization triggers throttling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62faddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between I/O wait and CPU utilization\n",
    "np.random.seed(42)  # Set seed for reproducible results\n",
    "io_wait_data = {\n",
    "    'time': list(range(100)),\n",
    "    'cpu_active': [max(0, min(100, 20 + 10*np.sin(i/10) + np.random.normal(0, 3))) for i in range(100)],\n",
    "    'io_wait': [max(0, min(100, 15 + 8*np.sin(i/10 + np.pi) + np.random.normal(0, 2))) for i in range(100)]\n",
    "}\n",
    "\n",
    "# Calculate idle time and create DataFrame directly in pandas for Altair\n",
    "import pandas as pd\n",
    "io_wait_pandas = pd.DataFrame(io_wait_data)\n",
    "io_wait_pandas['idle'] = 100 - io_wait_pandas['cpu_active'] - io_wait_pandas['io_wait']\n",
    "\n",
    "# Ensure proper data types for Altair\n",
    "io_wait_pandas = io_wait_pandas.astype({\n",
    "    'time': 'int64',\n",
    "    'cpu_active': 'float64',\n",
    "    'io_wait': 'float64',\n",
    "    'idle': 'float64'\n",
    "})\n",
    "\n",
    "# Melt the DataFrame before passing to Altair (avoids transform_fold type issues)\n",
    "io_wait_melted = io_wait_pandas.unpivot(\n",
    "    id_vars=['time'],\n",
    "    value_vars=['cpu_active', 'io_wait', 'idle'],\n",
    "    var_name='component',\n",
    "    value_name='percentage'\n",
    ")\n",
    "\n",
    "io_chart = alt.Chart(io_wait_melted).mark_area().encode(\n",
    "    x=alt.X('time:Q', title='Time'),\n",
    "    y=alt.Y('percentage:Q', stack='normalize', title='CPU State (%)'),\n",
    "    color=alt.Color('component:N',\n",
    "                    scale=alt.Scale(domain=['cpu_active', 'io_wait', 'idle'],\n",
    "                                  range=['#2ca02c', '#ff7f0e', '#d62728']),\n",
    "                    title='CPU State'),\n",
    "    tooltip=['time', 'component', 'percentage']\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=300,\n",
    "    title='Why CPUs Show Low Utilization: I/O Wait States'\n",
    ").interactive()\n",
    "\n",
    "io_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307516a4",
   "metadata": {},
   "source": [
    "## Part 2: Deep Dive - Understanding Each Workload Type\n",
    "\n",
    "Now let's explore WHY each workload type has its unique signature, backed by research data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for all workload types\n",
    "generator = WorkloadPatternGenerator(seed=42)\n",
    "workload_samples = {}\n",
    "\n",
    "for workload_type in WorkloadType:\n",
    "    df = generator.generate_time_series(\n",
    "        workload_type=workload_type,\n",
    "        start_time=datetime.now() - timedelta(days=7),\n",
    "        end_time=datetime.now(),\n",
    "        interval_minutes=60\n",
    "    )\n",
    "    workload_samples[workload_type.value] = df\n",
    "\n",
    "print(\"Generated samples for {} workload types\".format(len(workload_samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b86c1",
   "metadata": {},
   "source": [
    "### 2.1 Web Applications: Why 15% CPU and Business Hours Pattern?\n",
    "\n",
    "Web applications show low CPU utilization because they spend most time waiting for I/O operations.\n",
    "\n",
    "**Key Reasons:**\n",
    "- **Request/Response Model**: Each request triggers database queries, API calls\n",
    "- **Network Latency**: Waiting for client requests and responses\n",
    "- **Connection Pooling**: Maintaining idle connections for quick response\n",
    "- **Human Users**: Activity follows work schedules and timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze web application patterns\n",
    "web_app_data = workload_samples['web_application']\n",
    "\n",
    "# Calculate hourly averages to show business hours pattern\n",
    "hourly_stats = web_app_data.groupBy(\n",
    "    web_app_data['timestamp'].dt.hour().alias('hour')\n",
    ").agg(F.mean('cpu_utilization').alias('cpu_mean'), F.mean('memory_utilization').alias('memory_mean'), F.mean('waste_percentage').alias('waste_mean'))\n",
    "\n",
    "# Add explanation for each hour\n",
    "hourly_stats = hourly_stats.withColumn(\n",
    "    pl.when(F.col('hour').is_between(0, 5)).then(F.lit(\"Night - Minimal activity\"))\n",
    "    .when(F.col('hour').is_between(6, 8)).then(F.lit(\"Morning ramp-up\"))\n",
    "    .when(F.col('hour').is_between(9, 11)).then(F.lit(\"Peak morning activity\"))\n",
    "    .when(F.col('hour').is_between(12, 13)).then(F.lit(\"Lunch dip\"))\n",
    "    .when(F.col('hour').is_between(14, 16)).then(F.lit(\"Afternoon peak\"))\n",
    "    .when(F.col('hour').is_between(17, 18)).then(F.lit(\"End of day wind-down\"))\n",
    "    .otherwise(F.lit(\"Evening - Reduced activity\"))\n",
    "    .alias('period_explanation')\n",
    ")\n",
    "\n",
    "web_app_chart = alt.Chart(hourly_stats.toPandas()).mark_line(point=True).encode(\n",
    "    x=alt.X('hour:O', title='Hour of Day'),\n",
    "    y=alt.Y('cpu_mean:Q', title='Average CPU Utilization (%)'),\n",
    "    color=alt.value('#1f77b4'),\n",
    "    tooltip=['hour', 'cpu_mean', 'period_explanation']\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=350,\n",
    "    title='Web Applications: Why CPU Follows Business Hours'\n",
    ")\n",
    "\n",
    "memory_layer = alt.Chart(hourly_stats.toPandas()).mark_line(point=True, strokeDash=[5,5]).encode(\n",
    "    x='hour:O',\n",
    "    y=alt.Y('memory_mean:Q', title='Average Memory Utilization (%)'),\n",
    "    color=alt.value('#ff7f0e'),\n",
    "    tooltip=['hour', 'memory_mean', 'period_explanation']\n",
    ")\n",
    "\n",
    "(web_app_chart + memory_layer).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9476e1",
   "metadata": {},
   "source": [
    "### 2.2 Batch Processing: Why 70% Idle with 10x Peaks?\n",
    "\n",
    "Batch processing shows extreme waste because resources are reserved for scheduled jobs that run infrequently.\n",
    "\n",
    "**Key Reasons:**\n",
    "- **Schedule-Driven**: Jobs run at specific times (nightly, weekly)\n",
    "- **Resource Reservation**: Capacity kept available for batch windows\n",
    "- **Sequential Processing**: Cannot easily parallelize across time\n",
    "- **Data Dependencies**: Must wait for data to be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize batch processing patterns\n",
    "batch_data = workload_samples['batch_processing']\n",
    "\n",
    "# Create a view showing idle periods and spike patterns\n",
    "batch_sample = batch_data.limit(168)  # One week\n",
    "\n",
    "batch_chart = alt.Chart(batch_sample.toPandas()).mark_area(\n",
    "    line={'color':'darkblue'},\n",
    "    color=alt.Gradient(\n",
    "        gradient='linear',\n",
    "        stops=[alt.GradientStop(color='lightblue', offset=0),\n",
    "               alt.GradientStop(color='darkblue', offset=1)],\n",
    "        x1=0, y1=0, x2=0, y2=1\n",
    "    )\n",
    ").encode(\n",
    "    x=alt.X('timestamp:T', title='Time'),\n",
    "    y=alt.Y('cpu_utilization:Q', title='CPU Utilization (%)', scale=alt.Scale(domain=[0, 100])),\n",
    "    tooltip=['timestamp', 'cpu_utilization', 'is_idle']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300,\n",
    "    title='Batch Processing: Extreme Waste from Scheduled Execution'\n",
    ")\n",
    "\n",
    "# Add annotations for batch windows\n",
    "annotations_df = spark.createDataFrame({\n",
    "    'timestamp': [batch_sample['timestamp'][20], batch_sample['timestamp'][68],\n",
    "                  batch_sample['timestamp'][116], batch_sample['timestamp'][164]],\n",
    "    'cpu_utilization': [80, 85, 78, 82],\n",
    "    'label': ['Nightly ETL', 'Report Generation', 'Data Backup', 'Weekly Analytics']\n",
    "})\n",
    "\n",
    "annotations = alt.Chart(annotations_df.toPandas()).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontSize=10\n",
    ").encode(\n",
    "    x='timestamp:T',\n",
    "    y='cpu_utilization:Q',\n",
    "    text='label:N'\n",
    ")\n",
    "\n",
    "(batch_chart + annotations).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38870e",
   "metadata": {},
   "source": [
    "### 2.3 Machine Learning: Different Patterns for Training vs Inference\n",
    "\n",
    "ML workloads show distinct patterns based on their phase and hardware utilization.\n",
    "\n",
    "**Training (25% CPU, 40% Memory):**\n",
    "- **Batch Processing**: Loading data batches into memory\n",
    "- **GPU Offloading**: CPU coordinates, GPU computes\n",
    "- **Experimentation Gaps**: Idle between hyperparameter runs\n",
    "- **Checkpointing**: Periodic saves create I/O spikes\n",
    "\n",
    "**Inference (30% CPU, 45% Memory):**\n",
    "- **Model in Memory**: Loaded model consumes constant memory\n",
    "- **Request Serving**: More consistent than training\n",
    "- **Lower Variance**: Predictable computation per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ML Training vs Inference patterns\n",
    "ml_training = workload_samples['ml_training']\n",
    "ml_inference = workload_samples['ml_inference']\n",
    "\n",
    "# Sample 48 hours for detailed comparison\n",
    "comparison_hours = 48\n",
    "ml_comparison = spark.createDataFrame({\n",
    "    'hour': list(range(comparison_hours)),\n",
    "    'training_cpu': ml_training.head(comparison_hours)['cpu_utilization'].to_list(),\n",
    "    'training_memory': ml_training.head(comparison_hours)['memory_utilization'].to_list(),\n",
    "    'inference_cpu': ml_inference.head(comparison_hours)['cpu_utilization'].to_list(),\n",
    "    'inference_memory': ml_inference.head(comparison_hours)['memory_utilization'].to_list()\n",
    "})\n",
    "\n",
    "# Create side-by-side comparison\n",
    "ml_comparison_long = ml_comparison.unpivot(\n",
    "    index=['hour'],\n",
    "    on=['training_cpu', 'training_memory', 'inference_cpu', 'inference_memory']\n",
    ").withColumn(\n",
    "    pl.when(F.col('variable').contains('training')).then(F.lit('Training'))\n",
    "    .otherwise(F.lit('Inference')).alias('workload_type'),\n",
    "    pl.when(F.col('variable').contains('cpu')).then(F.lit('CPU'))\n",
    "    .otherwise(F.lit('Memory')).alias('resource_type')\n",
    ")\n",
    "\n",
    "ml_chart = alt.Chart(ml_comparison_long.toPandas()).mark_line().encode(\n",
    "    x=alt.X('hour:Q', title='Hour'),\n",
    "    y=alt.Y('value:Q', title='Utilization (%)'),\n",
    "    color=alt.Color('resource_type:N', title='Resource'),\n",
    "    strokeDash=alt.StrokeDash('workload_type:N', title='ML Phase'),\n",
    "    tooltip=['hour', 'value', 'workload_type', 'resource_type']\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=350,\n",
    "    title='ML Workloads: Why Training and Inference Differ'\n",
    ").interactive()\n",
    "\n",
    "ml_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b8f37",
   "metadata": {},
   "source": [
    "### 2.4 Databases: Why Memory-Heavy with Different OLTP vs OLAP Patterns?\n",
    "\n",
    "Databases prioritize memory for performance, but OLTP and OLAP have very different access patterns.\n",
    "\n",
    "**OLTP (20% CPU, 60% Memory):**\n",
    "- **Buffer Pool Cache**: Keep hot data in memory\n",
    "- **Connection Pools**: Each connection consumes memory\n",
    "- **Index Structures**: B-trees and hash indexes in RAM\n",
    "- **Transaction Logs**: Write-ahead logging for durability\n",
    "\n",
    "**OLAP (10% CPU, 30% Memory):**\n",
    "- **Columnar Storage**: Different memory access patterns\n",
    "- **Batch Queries**: Periodic analytical workloads\n",
    "- **Result Caching**: Store query results for reuse\n",
    "- **Compression**: CPU/memory tradeoff for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze database patterns\n",
    "db_oltp = workload_samples['database_oltp']\n",
    "db_olap = workload_samples['database_olap']\n",
    "\n",
    "# Show correlation between queries and resource usage\n",
    "db_comparison = spark.createDataFrame({\n",
    "    'workload': ['OLTP'] * 24 + ['OLAP'] * 24,\n",
    "    'hour': list(range(24)) * 2,\n",
    "    'cpu': (db_oltp.limit(24)['cpu_utilization'].to_list() +\n",
    "            db_olap.limit(24)['cpu_utilization'].to_list()),\n",
    "    'memory': (db_oltp.limit(24)['memory_utilization'].to_list() +\n",
    "               db_olap.limit(24)['memory_utilization'].to_list()),\n",
    "    'pattern_type': (\n",
    "        ['Transactional'] * 24 + ['Analytical'] * 24\n",
    "    )\n",
    "})\n",
    "\n",
    "db_scatter = alt.Chart(db_comparison.toPandas()).mark_circle(size=100).encode(\n",
    "    x=alt.X('cpu:Q', title='CPU Utilization (%)', scale=alt.Scale(domain=[0, 50])),\n",
    "    y=alt.Y('memory:Q', title='Memory Utilization (%)', scale=alt.Scale(domain=[0, 80])),\n",
    "    color=alt.Color('workload:N', title='Database Type', scale=alt.Scale(scheme='dark2')),\n",
    "    tooltip=['workload', 'cpu', 'memory', 'pattern_type']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Database Resource Patterns: OLTP vs OLAP'\n",
    ")\n",
    "\n",
    "# Add annotation regions\n",
    "regions = spark.createDataFrame({\n",
    "    'region': ['OLTP Zone', 'OLAP Zone'],\n",
    "    'cpu_center': [20, 10],\n",
    "    'memory_center': [60, 30],\n",
    "    'cpu_range': [10, 15],\n",
    "    'memory_range': [15, 20]\n",
    "})\n",
    "\n",
    "db_scatter.interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91cdda",
   "metadata": {},
   "source": [
    "### 2.5 Development Environments: Why 70% Waste?\n",
    "\n",
    "Development environments are the worst offenders for waste, and there are clear reasons why.\n",
    "\n",
    "**Root Causes of Waste:**\n",
    "- **24/7 Provisioning**: Resources allocated continuously\n",
    "- **8/5 Usage**: Only used during work hours on weekdays\n",
    "- **Overprovisioning**: \"Just in case\" resource allocation\n",
    "- **Forgotten Resources**: Developers forget to shut down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze development environment waste patterns\n",
    "dev_env = workload_samples['development_environment']\n",
    "\n",
    "# Calculate waste by day of week and hour\n",
    "dev_analysis = dev_env.withColumn(\n",
    "    dev_env['timestamp'].dt.weekday().alias('weekday'),\n",
    "    dev_env['timestamp'].dt.hour().alias('hour')\n",
    ")\n",
    "\n",
    "weekly_pattern = dev_analysis.groupBy('weekday').agg(F.mean('cpu_utilization').alias('cpu_mean'), F.mean('waste_percentage').alias('waste_mean')).withColumn(\n",
    "    pl.when(F.col('weekday') == 0).then(F.lit('Monday'))\n",
    "    .when(F.col('weekday') == 1).then(F.lit('Tuesday'))\n",
    "    .when(F.col('weekday') == 2).then(F.lit('Wednesday'))\n",
    "    .when(F.col('weekday') == 3).then(F.lit('Thursday'))\n",
    "    .when(F.col('weekday') == 4).then(F.lit('Friday'))\n",
    "    .when(F.col('weekday') == 5).then(F.lit('Saturday'))\n",
    "    .otherwise(F.lit('Sunday')).alias('day_name')\n",
    ")\n",
    "\n",
    "dev_waste_chart = alt.Chart(weekly_pattern.toPandas()).mark_bar().encode(\n",
    "    x=alt.X('day_name:N', title='Day of Week', sort=['Monday', 'Tuesday', 'Wednesday',\n",
    "                                                      'Thursday', 'Friday', 'Saturday', 'Sunday']),\n",
    "    y=alt.Y('waste_mean:Q', title='Average Waste (%)'),\n",
    "    color=alt.Color('waste_mean:Q', scale=alt.Scale(scheme='reds'), legend=None),\n",
    "    tooltip=['day_name', 'cpu_mean', 'waste_mean']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=350,\n",
    "    title='Development Environments: Why 70% Waste Occurs'\n",
    ")\n",
    "\n",
    "# Add text annotations\n",
    "text = alt.Chart(weekly_pattern.toPandas()).mark_text(dy=-10).encode(\n",
    "    x=alt.X('day_name:N', sort=['Monday', 'Tuesday', 'Wednesday',\n",
    "                                'Thursday', 'Friday', 'Saturday', 'Sunday']),\n",
    "    y=alt.Y('waste_mean:Q'),\n",
    "    text=alt.Text('waste_mean:Q', format='.1f')\n",
    ")\n",
    "\n",
    "(dev_waste_chart + text).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee7e5c",
   "metadata": {},
   "source": [
    "### 2.6 Serverless: Why Extreme Variance with Low Waste?\n",
    "\n",
    "Serverless shows unique patterns due to its pay-per-use model.\n",
    "\n",
    "**Distinctive Characteristics:**\n",
    "- **Cold Starts**: Initial invocations have high latency\n",
    "- **Auto-scaling**: Instant scale from 0 to thousands\n",
    "- **Micro-billing**: Pay only for actual execution time\n",
    "- **Stateless Design**: No persistent resource allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb782f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze serverless patterns\n",
    "serverless = workload_samples['serverless_function']\n",
    "\n",
    "# Show the extreme variance\n",
    "serverless_sample = serverless.limit(48)\n",
    "\n",
    "serverless_chart = alt.Chart(serverless_sample.toPandas()).mark_area(\n",
    "    line={'color':'purple'},\n",
    "    color=alt.Gradient(\n",
    "        gradient='linear',\n",
    "        stops=[alt.GradientStop(color='white', offset=0),\n",
    "               alt.GradientStop(color='purple', offset=1)],\n",
    "        x1=0, y1=0, x2=0, y2=1\n",
    "    ),\n",
    "    opacity=0.7\n",
    ").encode(\n",
    "    x=alt.X('timestamp:T', title='Time'),\n",
    "    y=alt.Y('cpu_utilization:Q', title='CPU Utilization (%)', scale=alt.Scale(domain=[0, 100])),\n",
    "    tooltip=['timestamp', 'cpu_utilization', 'waste_percentage']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300,\n",
    "    title='Serverless: Extreme Variance but Low Waste (Pay-per-Use)'\n",
    ")\n",
    "\n",
    "# Add cold start indicators\n",
    "cold_starts = serverless_sample.filter(F.col('cpu_utilization') > 80)\n",
    "cold_start_markers = alt.Chart(cold_starts.toPandas()).mark_circle(\n",
    "    color='red',\n",
    "    size=100\n",
    ").encode(\n",
    "    x='timestamp:T',\n",
    "    y='cpu_utilization:Q',\n",
    "    tooltip=[alt.Tooltip('timestamp:T', title='Cold Start At')]\n",
    ")\n",
    "\n",
    "(serverless_chart + cold_start_markers).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f4edb",
   "metadata": {},
   "source": [
    "## Part 3: Understanding Correlation Patterns\n",
    "\n",
    "Different workloads show distinct correlations between resource metrics, and understanding why helps with optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations for each workload type\n",
    "correlations = {}\n",
    "\n",
    "for workload_name, df in workload_samples.items():\n",
    "    cpu = df['cpu_utilization'].to_numpy()\n",
    "    memory = df['memory_utilization'].to_numpy()\n",
    "    network_in = df['network_in_mbps'].to_numpy()\n",
    "    disk = df['disk_iops'].to_numpy()\n",
    "\n",
    "    correlations[workload_name] = {\n",
    "        'cpu_memory': np.corrcoef(cpu, memory)[0, 1],\n",
    "        'cpu_network': np.corrcoef(cpu, network_in)[0, 1],\n",
    "        'cpu_disk': np.corrcoef(cpu, disk)[0, 1],\n",
    "        'memory_network': np.corrcoef(memory, network_in)[0, 1]\n",
    "    }\n",
    "\n",
    "# Create correlation heatmap data\n",
    "corr_data = []\n",
    "for workload, corr_values in correlations.items():\n",
    "    for metric_pair, correlation in corr_values.items():\n",
    "        corr_data.append({\n",
    "            'workload': workload.replace('_', ' ').title(),\n",
    "            'metric_pair': metric_pair.replace('_', ' ').title(),\n",
    "            'correlation': correlation\n",
    "        })\n",
    "\n",
    "corr_df = spark.createDataFrame(corr_data)\n",
    "\n",
    "# Create heatmap\n",
    "correlation_heatmap = alt.Chart(corr_df.toPandas()).mark_rect().encode(\n",
    "    x=alt.X('metric_pair:N', title='Metric Pair'),\n",
    "    y=alt.Y('workload:N', title='Workload Type'),\n",
    "    color=alt.Color('correlation:Q',\n",
    "                    scale=alt.Scale(scheme='redblue', domain=[-1, 1]),\n",
    "                    title='Correlation'),\n",
    "    tooltip=['workload', 'metric_pair', alt.Tooltip('correlation:Q', format='.3f')]\n",
    ").properties(\n",
    "    width=500,\n",
    "    height=400,\n",
    "    title='Why Different Workloads Show Different Correlations'\n",
    ").interactive()\n",
    "\n",
    "correlation_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d15961",
   "metadata": {},
   "source": [
    "### Explaining Correlation Patterns\n",
    "\n",
    "**Strong CPU-Memory Correlation (>0.7):**\n",
    "- **ML Training**: Loading batches requires both compute and memory\n",
    "- **Streaming**: Processing data streams uses both proportionally\n",
    "- **Why**: Data must be in memory to be processed\n",
    "\n",
    "**Weak CPU-Memory Correlation (<0.3):**\n",
    "- **Databases**: Memory for caching, CPU for queries (independent)\n",
    "- **Cache Layers**: High memory, low CPU consistently\n",
    "- **Why**: Memory serves different purpose than computation\n",
    "\n",
    "**CPU-Network Correlation:**\n",
    "- **Web Apps**: High correlation - requests drive processing\n",
    "- **Batch**: Low correlation - network for data transfer, CPU for processing\n",
    "- **Why**: Depends on whether network I/O drives computation\n",
    "\n",
    "## Part 4: Temporal Patterns and Autocorrelation\n",
    "\n",
    "Understanding why patterns persist over time helps with forecasting and capacity planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate autocorrelation for different workloads\n",
    "from scipy import signal\n",
    "\n",
    "autocorr_results = {}\n",
    "lags = list(range(1, 25))  # Check up to 24 hours\n",
    "\n",
    "for workload_name in ['web_application', 'batch_processing', 'streaming_pipeline']:\n",
    "    df = workload_samples[workload_name]\n",
    "    cpu_series = df['cpu_utilization'].to_numpy()\n",
    "\n",
    "    # Calculate autocorrelation\n",
    "    autocorr = []\n",
    "    for lag in lags:\n",
    "        if lag < len(cpu_series):\n",
    "            corr = np.corrcoef(cpu_series[:-lag], cpu_series[lag:])[0, 1]\n",
    "            autocorr.append(corr)\n",
    "        else:\n",
    "            autocorr.append(0)\n",
    "\n",
    "    autocorr_results[workload_name] = autocorr\n",
    "\n",
    "# Create visualization\n",
    "autocorr_data = []\n",
    "for workload, values in autocorr_results.items():\n",
    "    for lag, corr in zip(lags, values):\n",
    "        autocorr_data.append({\n",
    "            'workload': workload.replace('_', ' ').title(),\n",
    "            'lag_hours': lag,\n",
    "            'autocorrelation': corr\n",
    "        })\n",
    "\n",
    "autocorr_df = spark.createDataFrame(autocorr_data)\n",
    "\n",
    "autocorr_chart = alt.Chart(autocorr_df.toPandas()).mark_line(point=True).encode(\n",
    "    x=alt.X('lag_hours:Q', title='Lag (hours)'),\n",
    "    y=alt.Y('autocorrelation:Q', title='Autocorrelation', scale=alt.Scale(domain=[0, 1])),\n",
    "    color=alt.Color('workload:N', title='Workload Type'),\n",
    "    tooltip=['workload', 'lag_hours', alt.Tooltip('autocorrelation:Q', format='.3f')]\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=400,\n",
    "    title='Temporal Autocorrelation: Why Patterns Persist'\n",
    ").interactive()\n",
    "\n",
    "autocorr_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5049501f",
   "metadata": {},
   "source": [
    "### Why Autocorrelation Matters\n",
    "\n",
    "**High Autocorrelation (Web Apps, Streaming):**\n",
    "- **Gradual Changes**: User activity changes slowly\n",
    "- **Predictability**: Future similar to recent past\n",
    "- **Optimization**: Can forecast and pre-scale\n",
    "\n",
    "**Low Autocorrelation (Batch Processing):**\n",
    "- **Discrete Events**: Jobs start and stop abruptly\n",
    "- **Less Predictable**: Harder to forecast\n",
    "- **Optimization**: Need event-driven scaling\n",
    "\n",
    "## Part 5: Cost Implications and Optimization Opportunities\n",
    "\n",
    "Understanding signatures enables targeted optimization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate potential savings by workload type\n",
    "savings_analysis = []\n",
    "\n",
    "for workload_name, df in workload_samples.items():\n",
    "    avg_cpu = df['cpu_utilization'].mean()\n",
    "    avg_memory = df['memory_utilization'].mean()\n",
    "    avg_waste = df['waste_percentage'].mean()\n",
    "\n",
    "    # Calculate optimization potential\n",
    "    if avg_cpu < 20:  # Low utilization\n",
    "        optimization_strategy = \"Aggressive auto-scaling or serverless\"\n",
    "        potential_savings = avg_waste * 0.7  # Can eliminate 70% of waste\n",
    "    elif avg_waste > 50:  # High waste\n",
    "        optimization_strategy = \"Right-sizing and scheduling\"\n",
    "        potential_savings = avg_waste * 0.6\n",
    "    elif 'database' in workload_name:  # Databases\n",
    "        optimization_strategy = \"Reserved instances and caching\"\n",
    "        potential_savings = avg_waste * 0.4\n",
    "    else:\n",
    "        optimization_strategy = \"Standard auto-scaling\"\n",
    "        potential_savings = avg_waste * 0.5\n",
    "\n",
    "    savings_analysis.append({\n",
    "        'workload': workload_name.replace('_', ' ').title(),\n",
    "        'current_waste': avg_waste,\n",
    "        'potential_savings': potential_savings,\n",
    "        'optimization_strategy': optimization_strategy,\n",
    "        'avg_cpu': avg_cpu,\n",
    "        'avg_memory': avg_memory\n",
    "    })\n",
    "\n",
    "savings_df = spark.createDataFrame(savings_analysis)\n",
    "\n",
    "# Create savings opportunity chart\n",
    "savings_chart = alt.Chart(savings_df.toPandas()).mark_bar().encode(\n",
    "    x=alt.X('potential_savings:Q', title='Potential Savings (%)'),\n",
    "    y=alt.Y('workload:N', title='Workload Type',\n",
    "            sort=alt.EncodingSortField(field='potential_savings', order='descending')),\n",
    "    color=alt.Color('optimization_strategy:N', title='Recommended Strategy'),\n",
    "    tooltip=['workload', 'current_waste', 'potential_savings', 'optimization_strategy']\n",
    ").properties(\n",
    "    width=700,\n",
    "    height=400,\n",
    "    title='Optimization Opportunities by Understanding Signatures'\n",
    ").interactive()\n",
    "\n",
    "savings_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc2f07",
   "metadata": {},
   "source": [
    "## Key Takeaways: Why Signatures Matter\n",
    "\n",
    "Understanding **why** different workloads have distinct signatures enables:\n",
    "\n",
    "1. **Right-sizing**: Match resources to actual needs, not peaks\n",
    "2. **Scheduling**: Run batch jobs during web app quiet times\n",
    "3. **Architecture Decisions**: Choose serverless for variable loads\n",
    "4. **Cost Optimization**: Target biggest waste sources first\n",
    "5. **Capacity Planning**: Predict future needs from patterns\n",
    "\n",
    "### The Math Behind the Patterns\n",
    "\n",
    "For those interested in the statistical foundations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ec6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the mathematical relationships\n",
    "math_explanation = \"\"\"\n",
    "### Statistical Properties of Workload Signatures\n",
    "\n",
    "**1. Mean Utilization (μ)**: Baseline resource consumption\n",
    "   - Web Apps: μ_cpu ≈ 15%, μ_mem ≈ 35%\n",
    "   - Batch: μ_cpu ≈ 8%, μ_mem ≈ 15%\n",
    "\n",
    "**2. Variance (σ²)**: Variability in resource usage\n",
    "   - High variance → Unpredictable (Serverless: σ² > 40)\n",
    "   - Low variance → Stable (Streaming: σ² < 10)\n",
    "\n",
    "**3. Correlation (ρ)**: Relationship between metrics\n",
    "   ρ(CPU, Memory) = Cov(CPU, Memory) / (σ_cpu * σ_mem)\n",
    "   - ML Training: ρ ≈ 0.8 (strong positive)\n",
    "   - Database: ρ ≈ 0.2 (weak)\n",
    "\n",
    "**4. Autocorrelation (r_k)**: Temporal dependency\n",
    "   r_k = Cov(X_t, X_{t+k}) / Var(X_t)\n",
    "   - Web Apps: r_1 ≈ 0.8 (strong persistence)\n",
    "   - Batch: r_1 ≈ 0.3 (weak persistence)\n",
    "\n",
    "**5. Waste Function**: W = (Provisioned - Used) / Provisioned\n",
    "   - Development: W ≈ 0.7 (70% waste)\n",
    "   - Streaming: W ≈ 0.2 (20% waste)\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(math_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1975c",
   "metadata": {},
   "source": [
    "## Conclusion: From Understanding to Action\n",
    "\n",
    "This guide has explored the fundamental reasons why different cloud workloads exhibit distinct resource utilization signatures. By understanding these patterns, we can:\n",
    "\n",
    "1. **Predict** future resource needs with greater accuracy\n",
    "2. **Optimize** resource allocation to reduce waste\n",
    "3. **Design** better architectures that match workload characteristics\n",
    "4. **Save** significant costs through targeted interventions\n",
    "\n",
    "The shocking reality of 13% average CPU utilization and 30-32% waste isn't just a statistic—it's an opportunity. By understanding the \"why\" behind these patterns, we can build more efficient cloud infrastructure.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To apply these insights:\n",
    "1. Profile your own workloads to identify their signatures\n",
    "2. Compare against these patterns to find optimization opportunities\n",
    "3. Implement targeted strategies based on workload type\n",
    "4. Monitor and iterate to continuously improve efficiency\n",
    "\n",
    "Remember: Every workload is unique, but understanding these fundamental patterns provides a foundation for optimization."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3",
   "formats": "notebooks//md:myst,notebooks/_build//ipynb"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
