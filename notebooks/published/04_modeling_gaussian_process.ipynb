{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f5d7666",
   "metadata": {},
   "source": [
    "# Gaussian Process Modeling for IOPS Web Server KPI\n",
    "\n",
    "**Objective:** Build a robust Gaussian Process model for operational time series forecasting and anomaly detection using GPyTorch with sparse variational approximations.\n",
    "\n",
    "**Key Innovation:** Student-t likelihood + composite periodic kernels trained on ALL data (including anomalies) for production-ready robustness.\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Auto-Reload Configuration\n",
    "\n",
    "**Hot Reload**: Enable automatic reloading of library code (src/) without kernel restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce21794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload: Picks up library changes without kernel restart\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8f2eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930483b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "# Local: Uses installed hellocloud\n",
    "# Colab: Installs from GitHub\n",
    "try:\n",
    "    import hellocloud\n",
    "except ImportError:\n",
    "    !pip install -q git+https://github.com/nehalecky/hello-cloud.git\n",
    "    import hellocloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74346e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "# Polars replaced with PySpark\n",
    "\n",
    "# PyTorch and GPyTorch\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.likelihoods import StudentTLikelihood, GaussianLikelihood\n",
    "\n",
    "# Cloud simulation library (our GP implementation)\n",
    "from hellocloud.modeling.gaussian_process import (\n",
    "    CompositePeriodicKernel,\n",
    "    SparseGPModel,\n",
    "    initialize_inducing_points,\n",
    "    train_gp_model,\n",
    "    save_model,\n",
    "    load_model,\n",
    "    compute_metrics,\n",
    "    compute_anomaly_metrics,\n",
    "    compute_prediction_intervals,\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "from scipy.stats import norm, t as student_t\n",
    "\n",
    "# Configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device selection\n",
    "# NOTE: MPS (Apple Silicon) is not used - GPyTorch's variational inference requires\n",
    "# operations (_linalg_eigh) not yet implemented in PyTorch's MPS backend.\n",
    "# Using CPU is reliable and still performs well for this dataset size.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"✓ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(f\"✓ Using CPU\")\n",
    "\n",
    "# Use float32 for all operations (standard for deep learning)\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa4cdd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. EDA Recap: Key Findings\n",
    "\n",
    "From our exploratory data analysis (`03_iops_web_server_eda.ipynb`), we discovered:\n",
    "\n",
    "### **Dataset Characteristics**\n",
    "- **Training:** 146,255 samples with 285 labeled anomalies (0.19%)\n",
    "- **Testing:** 149,130 samples with 991 labeled anomalies (0.66%)\n",
    "- **KPI:** IOPS (I/O operations per second) from production web server\n",
    "\n",
    "### **Two-Scale Periodic Pattern**\n",
    "\n",
    "**SLOW Component (Sawtooth Envelope):**\n",
    "- Period: ~1250 timesteps (≈21 hours)\n",
    "- Shape: Linear ramp-up → sharp drop/reset\n",
    "- Operational interpretation: Daily accumulation + overnight reset\n",
    "\n",
    "**FAST Component (Sinusoidal Carrier):**\n",
    "- Period: ~250 timesteps (≈4 hours)\n",
    "- 5 complete oscillations per sawtooth cycle (valley to valley)\n",
    "- Operational interpretation: Regular micro-cycles within operational windows\n",
    "\n",
    "### **Statistical Properties**\n",
    "- **Normal periods:** Mean ≈ 34.4, Std ≈ 3.9\n",
    "- **Anomalous periods:** Mean ≈ 39.4, Std ≈ 15.8 (4× larger variance)\n",
    "- **KS test:** Highly significant distributional differences (D=0.417, p<0.001)\n",
    "\n",
    "### **Modeling Implications**\n",
    "- **Robust approach needed:** Student-t likelihood handles heavy tails\n",
    "- **Sparse GP required:** Dataset size (n=146,255) requires inducing points\n",
    "- **Composite kernel:** Capture sawtooth × sinusoidal interaction\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664741a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IOPS data from HuggingFace (same as EDA notebook)\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"https://huggingface.co/datasets/AutonLab/Timeseries-PILE/resolve/main\"\n",
    "kpi_id = \"KPI-05f10d3a-239c-3bef-9bdc-a2feeb0037aa\"\n",
    "\n",
    "# Load train and test splits\n",
    "train_url = f\"{base_url}/anomaly_detection/TSB-UAD-Public/IOPS/{kpi_id}.train.out\"\n",
    "test_url = f\"{base_url}/anomaly_detection/TSB-UAD-Public/IOPS/{kpi_id}.test.out\"\n",
    "\n",
    "print(\"Downloading IOPS data from HuggingFace...\")\n",
    "train_pd = pd.read_csv(train_url, header=None, names=['value', 'label'])\n",
    "test_pd = pd.read_csv(test_url, header=None, names=['value', 'label'])\n",
    "\n",
    "# Convert to Polars\n",
    "# NOTE: Dataset has no timestamps - we create sequential indices (1-minute intervals)\n",
    "train_df = spark.createDataFrame({\n",
    "    'timestamp': np.arange(len(train_pd)),\n",
    "    'value': train_pd['value'].values,\n",
    "    'is_anomaly': train_pd['label'].values.astype(bool)\n",
    "})\n",
    "\n",
    "test_df = spark.createDataFrame({\n",
    "    'timestamp': np.arange(len(test_pd)),\n",
    "    'value': test_pd['value'].values,\n",
    "    'is_anomaly': test_pd['label'].values.astype(bool)\n",
    "})\n",
    "\n",
    "print(f\"✓ Data loaded successfully\")\n",
    "print(f\"  Training: {len(train_df):,} samples\")\n",
    "print(f\"  Test: {len(test_df):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract arrays for modeling\n",
    "X_train = train_df['timestamp'].to_numpy().reshape(-1, 1).astype(np.float64)\n",
    "y_train = train_df['value'].to_numpy().astype(np.float64)\n",
    "anomaly_train = train_df['is_anomaly'].to_numpy()\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_anomalies_train = anomaly_train.sum()\n",
    "\n",
    "print(f\"Training data:\")\n",
    "print(f\"  Total samples: {n_train:,}\")\n",
    "print(f\"  Anomalies: {n_anomalies_train} ({100*n_anomalies_train/n_train:.2f}%)\")\n",
    "print(f\"  Time range: {X_train.min():.0f} → {X_train.max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test arrays\n",
    "X_test = test_df['timestamp'].to_numpy().reshape(-1, 1).astype(np.float64)\n",
    "y_test = test_df['value'].to_numpy().astype(np.float64)\n",
    "anomaly_test = test_df['is_anomaly'].to_numpy()\n",
    "\n",
    "n_test = len(X_test)\n",
    "n_anomalies_test = anomaly_test.sum()\n",
    "\n",
    "print(f\"Test data:\")\n",
    "print(f\"  Total samples: {n_test:,}\")\n",
    "print(f\"  Anomalies: {n_anomalies_test} ({100*n_anomalies_test/n_test:.2f}%)\")\n",
    "print(f\"  Time range: {X_test.min():.0f} → {X_test.max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize timestamps for numerical stability\n",
    "X_min = X_train.min()\n",
    "X_max = X_train.max()\n",
    "X_range = X_max - X_min\n",
    "\n",
    "X_train_norm = (X_train - X_min) / X_range\n",
    "X_test_norm = (X_test - X_min) / X_range\n",
    "\n",
    "print(f\"Normalized timestamps:\")\n",
    "print(f\"  Training: {X_train_norm.min():.6f} → {X_train_norm.max():.6f}\")\n",
    "print(f\"  Test: {X_test_norm.min():.6f} → {X_test_norm.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842877a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean training set (exclude anomalies) for baseline model\n",
    "mask_clean = ~anomaly_train.astype(bool)\n",
    "X_train_clean = X_train_norm[mask_clean]\n",
    "y_train_clean = y_train[mask_clean]\n",
    "\n",
    "print(f\"Clean training set (traditional approach):\")\n",
    "print(f\"  Samples: {len(X_train_clean):,} (excluded {n_anomalies_train} anomalies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors (use dtype from device selection)\n",
    "X_train_t = torch.tensor(X_train_norm, dtype=dtype, device=device)\n",
    "y_train_t = torch.tensor(y_train, dtype=dtype, device=device)\n",
    "\n",
    "X_train_clean_t = torch.tensor(X_train_clean, dtype=dtype, device=device)\n",
    "y_train_clean_t = torch.tensor(y_train_clean, dtype=dtype, device=device)\n",
    "\n",
    "X_test_t = torch.tensor(X_test_norm, dtype=dtype, device=device)\n",
    "y_test_t = torch.tensor(y_test, dtype=dtype, device=device)\n",
    "\n",
    "print(f\"Tensor shapes:\")\n",
    "print(f\"  X_train: {X_train_t.shape}, y_train: {y_train_t.shape}\")\n",
    "print(f\"  X_train_clean: {X_train_clean_t.shape}, y_train_clean: {y_train_clean_t.shape}\")\n",
    "print(f\"  X_test: {X_test_t.shape}, y_test: {y_test_t.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7481eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical stability configuration for Cholesky decomposition\n",
    "cholesky_jitter = 1e-3  # Diagonal regularization\n",
    "cholesky_max_tries = 10  # Retry attempts if decomposition fails\n",
    "\n",
    "print(f\"✓ Numerical stability: jitter={cholesky_jitter}, max_tries={cholesky_max_tries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02323af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Exact GP Baseline (Simple Approach)\n",
    "\n",
    "### **Why Exact GP?**\n",
    "\n",
    "The sparse variational GP approach (sections 5-9) uses inducing points for scalability:\n",
    "- **Dataset:** 146k timesteps\n",
    "- **Inducing points:** M=200\n",
    "- **Spacing:** ~730 timesteps apart\n",
    "- **Fast period:** 250 timesteps\n",
    "\n",
    "**Problem:** With inducing points 3× the period spacing, the variational approximation cannot capture fine periodic structure. The model smooths over the patterns.\n",
    "\n",
    "**Solution:** Use **exact GP** on a subset of data (following [GPyTorch simple example](https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html)):\n",
    "- No inducing points needed\n",
    "- Can capture true periodic structure\n",
    "- Computational cost O(n³) limits to n≈5-10k points\n",
    "\n",
    "### 4.1 Subsample Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1808be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample to make exact GP tractable\n",
    "# Take every Nth point to get ~5000 samples\n",
    "subsample_factor = 30  # 146,255 / 30 ≈ 4,875 points\n",
    "\n",
    "# Create subsampled indices (evenly spaced)\n",
    "subsample_indices = np.arange(0, len(X_train), subsample_factor)\n",
    "\n",
    "X_train_sub = X_train[subsample_indices]\n",
    "y_train_sub = y_train[subsample_indices]\n",
    "anomaly_train_sub = anomaly_train[subsample_indices]\n",
    "\n",
    "print(f\"Subsampled training data:\")\n",
    "print(f\"  Original: {len(X_train):,} samples\")\n",
    "print(f\"  Subsampled: {len(X_train_sub):,} samples (every {subsample_factor}th point)\")\n",
    "print(f\"  Reduction: {100*(1-len(X_train_sub)/len(X_train)):.1f}%\")\n",
    "print(f\"  Anomalies: {anomaly_train_sub.sum()} ({100*anomaly_train_sub.sum()/len(X_train_sub):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87dde7",
   "metadata": {},
   "source": [
    "### 4.1.1 Subsampling Validation: Does It Preserve Signal Structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Verify subsampling doesn't destroy the signal\n",
    "# Save all outputs to file for easy reference\n",
    "\n",
    "output_file = '../subsampling_validation.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"SUBSAMPLING VALIDATION REPORT\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    # Statistical comparison\n",
    "    f.write(\"Statistical Comparison:\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"{'Metric':<20} {'Full Data':<15} {'Subsampled':<15} {'Difference':<15}\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    metrics = {\n",
    "        'Mean': (y_train.mean(), y_train_sub.mean()),\n",
    "        'Std': (y_train.std(), y_train_sub.std()),\n",
    "        'Variance': (y_train.var(), y_train_sub.var()),\n",
    "        'Min': (y_train.min(), y_train_sub.min()),\n",
    "        'Max': (y_train.max(), y_train_sub.max()),\n",
    "        'Q25': (np.percentile(y_train, 25), np.percentile(y_train_sub, 25)),\n",
    "        'Median': (np.median(y_train), np.median(y_train_sub)),\n",
    "        'Q75': (np.percentile(y_train, 75), np.percentile(y_train_sub, 75)),\n",
    "    }\n",
    "\n",
    "    for metric, (full, sub) in metrics.items():\n",
    "        diff = ((sub - full) / full) * 100 if full != 0 else 0\n",
    "        line = f\"{metric:<20} {full:<15.3f} {sub:<15.3f} {diff:>+6.1f}%\\n\"\n",
    "        f.write(line)\n",
    "        print(line, end='')\n",
    "\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    print()\n",
    "\n",
    "    # Autocorrelation comparison (critical for temporal structure)\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    # Compute autocorrelation at key lags\n",
    "    lags_to_check = [1, 10, 50, 250, 1250]  # Include our identified periods\n",
    "\n",
    "    f.write(\"Autocorrelation Comparison:\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"{'Lag':<10} {'Full Data':<15} {'Subsampled':<15} {'Difference':<15}\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    print(\"Autocorrelation Comparison:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for lag in lags_to_check:\n",
    "        # Full data autocorrelation\n",
    "        if lag < len(y_train):\n",
    "            acf_full = pearsonr(y_train[:-lag], y_train[lag:])[0]\n",
    "        else:\n",
    "            acf_full = np.nan\n",
    "\n",
    "        # Subsampled autocorrelation (adjust lag for subsampling)\n",
    "        lag_sub = lag // subsample_factor\n",
    "        if lag_sub > 0 and lag_sub < len(y_train_sub):\n",
    "            acf_sub = pearsonr(y_train_sub[:-lag_sub], y_train_sub[lag_sub:])[0]\n",
    "        else:\n",
    "            acf_sub = np.nan\n",
    "\n",
    "        if not np.isnan(acf_full) and not np.isnan(acf_sub):\n",
    "            diff = acf_sub - acf_full\n",
    "            line = f\"{lag:<10} {acf_full:<15.3f} {acf_sub:<15.3f} {diff:>+6.3f}\\n\"\n",
    "            f.write(line)\n",
    "            print(line, end='')\n",
    "        else:\n",
    "            line = f\"{lag:<10} {str(acf_full):<15} {str(acf_sub):<15} {'N/A':<15}\\n\"\n",
    "            f.write(line)\n",
    "            print(line, end='')\n",
    "\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n✓ Validation report saved to: {output_file}\")\n",
    "print(f\"  Use: cat {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ed195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual validation: overlay subsampled points on full data\n",
    "fig, axes = plt.subplots(3, 1, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: First 5000 timesteps - Full data vs subsampled\n",
    "n_viz = 5000\n",
    "axes[0].plot(X_train[:n_viz].flatten(), y_train[:n_viz], 'k-', linewidth=0.5, alpha=0.5, label='Full data')\n",
    "axes[0].scatter(X_train_sub[:n_viz//subsample_factor], y_train_sub[:n_viz//subsample_factor],\n",
    "                c='red', s=20, alpha=0.7, zorder=5, label=f'Subsampled (every {subsample_factor}th)')\n",
    "axes[0].set_title(f'Subsampling Validation: First {n_viz} Timesteps', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Timestamp')\n",
    "axes[0].set_ylabel('IOPS Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Zoom into 2 periods of fast oscillation (~500 timesteps)\n",
    "zoom_start = 10000\n",
    "zoom_end = zoom_start + 500\n",
    "zoom_indices = (X_train.flatten() >= zoom_start) & (X_train.flatten() < zoom_end)\n",
    "zoom_indices_sub = (X_train_sub.flatten() >= zoom_start) & (X_train_sub.flatten() < zoom_end)\n",
    "\n",
    "axes[1].plot(X_train[zoom_indices].flatten(), y_train[zoom_indices], 'k-', linewidth=1.5, alpha=0.7, label='Full data')\n",
    "axes[1].scatter(X_train_sub[zoom_indices_sub], y_train_sub[zoom_indices_sub],\n",
    "                c='red', s=50, alpha=0.8, zorder=5, label=f'Subsampled points')\n",
    "axes[1].set_title(f'Zoom: Timesteps {zoom_start}-{zoom_end} (~2 Fast Periods)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Timestamp')\n",
    "axes[1].set_ylabel('IOPS Value')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Distribution comparison (histogram + KDE)\n",
    "axes[2].hist(y_train, bins=50, alpha=0.5, density=True, color='black', label='Full data')\n",
    "axes[2].hist(y_train_sub, bins=50, alpha=0.5, density=True, color='red', label='Subsampled')\n",
    "axes[2].set_title('Value Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('IOPS Value')\n",
    "axes[2].set_ylabel('Density')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "visual_plot_file = '../subsampling_visual_validation.png'\n",
    "plt.savefig(visual_plot_file, dpi=150, bbox_inches='tight')\n",
    "print(f\"✓ Visual validation plot saved to: {visual_plot_file}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency domain analysis: Power spectral density comparison\n",
    "from scipy import signal\n",
    "\n",
    "# Compute PSD for full data (use Welch's method for long series)\n",
    "freqs_full, psd_full = signal.welch(y_train, fs=1.0, nperseg=min(2048, len(y_train)//4))\n",
    "\n",
    "# Compute PSD for subsampled data\n",
    "freqs_sub, psd_sub = signal.welch(y_train_sub, fs=1.0/subsample_factor, nperseg=min(2048, len(y_train_sub)//4))\n",
    "\n",
    "# Plot power spectral density\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "ax.semilogy(freqs_full, psd_full, 'k-', linewidth=2, alpha=0.7, label='Full data PSD')\n",
    "ax.semilogy(freqs_sub, psd_sub, 'r--', linewidth=2, alpha=0.7, label='Subsampled PSD')\n",
    "\n",
    "# Mark expected frequencies\n",
    "expected_fast_freq = 1.0 / 250  # Fast period\n",
    "expected_slow_freq = 1.0 / 1250  # Slow period\n",
    "\n",
    "ax.axvline(expected_fast_freq, color='blue', linestyle=':', linewidth=2, alpha=0.5, label=f'Expected fast freq (1/250)')\n",
    "ax.axvline(expected_slow_freq, color='green', linestyle=':', linewidth=2, alpha=0.5, label=f'Expected slow freq (1/1250)')\n",
    "\n",
    "# Nyquist frequency for subsampled data\n",
    "nyquist_sub = 1.0 / (2 * subsample_factor)\n",
    "ax.axvline(nyquist_sub, color='orange', linestyle='--', linewidth=2, alpha=0.7, label=f'Subsampled Nyquist (1/{2*subsample_factor})')\n",
    "\n",
    "ax.set_xlabel('Frequency (cycles/timestep)', fontsize=12)\n",
    "ax.set_ylabel('Power Spectral Density', fontsize=12)\n",
    "ax.set_title('Frequency Content: Full vs Subsampled Data', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, which='both')\n",
    "ax.set_xlim([freqs_full[1], 0.05])  # Focus on low frequencies\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save PSD plot\n",
    "psd_plot_file = '../subsampling_psd_analysis.png'\n",
    "plt.savefig(psd_plot_file, dpi=150, bbox_inches='tight')\n",
    "print(f\"✓ PSD analysis plot saved to: {psd_plot_file}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Check if fast frequency is above Nyquist - SAVE TO FILE\n",
    "aliasing_file = '../subsampling_aliasing_analysis.txt'\n",
    "\n",
    "with open(aliasing_file, 'w') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"ALIASING ANALYSIS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(f\"Fast period: 250 timesteps → frequency: {expected_fast_freq:.6f} cycles/timestep\\n\")\n",
    "    f.write(f\"Slow period: 1250 timesteps → frequency: {expected_slow_freq:.6f} cycles/timestep\\n\")\n",
    "    f.write(f\"Subsampling factor: {subsample_factor}\\n\")\n",
    "    f.write(f\"Subsampled Nyquist frequency: {nyquist_sub:.6f} cycles/timestep\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    if expected_fast_freq > nyquist_sub:\n",
    "        verdict = \"⚠️  ALIASING DETECTED!\"\n",
    "        f.write(verdict + \"\\n\")\n",
    "        f.write(f\"   Fast frequency ({expected_fast_freq:.6f}) > Nyquist ({nyquist_sub:.6f})\\n\")\n",
    "        f.write(f\"   Subsampling CANNOT capture 250-timestep oscillations!\\n\")\n",
    "        f.write(f\"   Need subsampling factor ≤ {int(250/2)} to avoid aliasing\\n\")\n",
    "    else:\n",
    "        verdict = \"✓ No aliasing - fast frequency below Nyquist\"\n",
    "        f.write(verdict + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"NOTE: No aliasing doesn't guarantee signal preservation!\\n\")\n",
    "        f.write(\"Check visual validation plots to confirm pattern capture.\\n\")\n",
    "\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Print to console as well\n",
    "print()\n",
    "with open(aliasing_file, 'r') as f:\n",
    "    print(f.read())\n",
    "\n",
    "print(f\"\\n✓ Aliasing analysis saved to: {aliasing_file}\")\n",
    "print(f\"  Use: cat {aliasing_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize subsampled data (same normalization as full dataset)\n",
    "X_train_sub_norm = (X_train_sub - X_min) / X_range\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_sub_t = torch.tensor(X_train_sub_norm, dtype=dtype, device=device)\n",
    "y_train_sub_t = torch.tensor(y_train_sub, dtype=dtype, device=device)\n",
    "\n",
    "print(f\"Subsampled tensor shapes:\")\n",
    "print(f\"  X: {X_train_sub_t.shape}\")\n",
    "print(f\"  y: {y_train_sub_t.shape}\")\n",
    "print(f\"  Normalized range: [{X_train_sub_norm.min():.6f}, {X_train_sub_norm.max():.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1b31b2",
   "metadata": {},
   "source": [
    "### 4.2 Exact GP Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, PeriodicKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "\n",
    "class ExactGPModel(ExactGP):\n",
    "    \"\"\"\n",
    "    Exact GP model (no inducing points) - follows GPyTorch simple example pattern.\n",
    "\n",
    "    This is computationally expensive (O(n³)) but can capture fine structure\n",
    "    without variational approximation.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_x, train_y, likelihood, kernel_type='rbf'):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "\n",
    "        # Mean function - initialize to data mean\n",
    "        self.mean_module = ConstantMean()\n",
    "\n",
    "        # Kernel selection\n",
    "        if kernel_type == 'rbf':\n",
    "            # Simple RBF kernel (baseline)\n",
    "            self.covar_module = ScaleKernel(RBFKernel())\n",
    "        elif kernel_type == 'periodic':\n",
    "            # RBF + Periodic (multi-scale patterns)\n",
    "            slow_period = 1250 / X_range\n",
    "            fast_period = 250 / X_range\n",
    "\n",
    "            slow_periodic = ScaleKernel(PeriodicKernel())\n",
    "            slow_periodic.base_kernel.period_length = slow_period\n",
    "            slow_periodic.base_kernel.raw_period_length.requires_grad = False\n",
    "\n",
    "            fast_periodic = ScaleKernel(PeriodicKernel())\n",
    "            fast_periodic.base_kernel.period_length = fast_period\n",
    "            fast_periodic.base_kernel.raw_period_length.requires_grad = False\n",
    "\n",
    "            rbf_component = ScaleKernel(RBFKernel())\n",
    "\n",
    "            # Additive kernel\n",
    "            self.covar_module = slow_periodic + fast_periodic + rbf_component\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown kernel_type: {kernel_type}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "print(\"✓ Exact GP model class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6f52c",
   "metadata": {},
   "source": [
    "### 4.3 Train Exact GP with RBF Kernel (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d81c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and likelihood\n",
    "likelihood_exact_rbf = GaussianLikelihood()\n",
    "model_exact_rbf = ExactGPModel(X_train_sub_t, y_train_sub_t, likelihood_exact_rbf, kernel_type='rbf')\n",
    "\n",
    "# Initialize mean to data mean\n",
    "model_exact_rbf.mean_module.constant.data.fill_(y_train_sub.mean())\n",
    "\n",
    "# Move to device\n",
    "model_exact_rbf = model_exact_rbf.to(device)\n",
    "likelihood_exact_rbf = likelihood_exact_rbf.to(device)\n",
    "\n",
    "print(\"✓ Exact GP (RBF kernel) initialized\")\n",
    "print(f\"  Kernel: RBF\")\n",
    "print(f\"  Training samples: {len(X_train_sub_t):,}\")\n",
    "print(f\"  Mean initialized to: {model_exact_rbf.mean_module.constant.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a20f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop - standard exact GP training (like GPyTorch example)\n",
    "model_exact_rbf.train()\n",
    "likelihood_exact_rbf.train()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = torch.optim.Adam(model_exact_rbf.parameters(), lr=0.1)\n",
    "\n",
    "# Marginal log likelihood\n",
    "mll = ExactMarginalLogLikelihood(likelihood_exact_rbf, model_exact_rbf)\n",
    "\n",
    "# Training\n",
    "n_epochs_exact = 50\n",
    "losses_exact_rbf = []\n",
    "\n",
    "print(f\"Training exact GP (RBF) for {n_epochs_exact} epochs...\")\n",
    "for epoch in range(n_epochs_exact):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_exact_rbf(X_train_sub_t)\n",
    "    loss = -mll(output, y_train_sub_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses_exact_rbf.append(loss.item())\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"  Epoch {epoch+1}/{n_epochs_exact} - Loss: {loss.item():.3f}\")\n",
    "\n",
    "print(f\"✓ Training complete - Final loss: {losses_exact_rbf[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc369673",
   "metadata": {},
   "source": [
    "### 4.4 Evaluate Exact GP (RBF Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "model_exact_rbf.eval()\n",
    "likelihood_exact_rbf.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    pred_dist_rbf = likelihood_exact_rbf(model_exact_rbf(X_test_t))\n",
    "    mean_exact_rbf = pred_dist_rbf.mean.cpu().numpy()\n",
    "    std_exact_rbf = pred_dist_rbf.stddev.cpu().numpy()\n",
    "\n",
    "# Compute metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "rmse_rbf = np.sqrt(mean_squared_error(y_test, mean_exact_rbf))\n",
    "mae_rbf = mean_absolute_error(y_test, mean_exact_rbf)\n",
    "r2_rbf = r2_score(y_test, mean_exact_rbf)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXACT GP (RBF KERNEL) - BASELINE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"RMSE: {rmse_rbf:.3f}\")\n",
    "print(f\"MAE:  {mae_rbf:.3f}\")\n",
    "print(f\"R²:   {r2_rbf:.3f}\")\n",
    "print()\n",
    "print(f\"Prediction range: [{mean_exact_rbf.min():.2f}, {mean_exact_rbf.max():.2f}]\")\n",
    "print(f\"Data range:       [{y_test.min():.2f}, {y_test.max():.2f}]\")\n",
    "print(f\"Prediction variance: {mean_exact_rbf.var():.3f}\")\n",
    "print(f\"Data variance:       {y_test.var():.3f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 1000 predictions\n",
    "n_viz = 1000\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Predictions vs actual\n",
    "axes[0].plot(y_test[:n_viz], 'k-', linewidth=1, label='Actual', alpha=0.7)\n",
    "axes[0].plot(mean_exact_rbf[:n_viz], 'b--', linewidth=1.5, label='Exact GP (RBF) predictions')\n",
    "axes[0].fill_between(\n",
    "    np.arange(n_viz),\n",
    "    mean_exact_rbf[:n_viz] - 2*std_exact_rbf[:n_viz],\n",
    "    mean_exact_rbf[:n_viz] + 2*std_exact_rbf[:n_viz],\n",
    "    alpha=0.2,\n",
    "    color='blue',\n",
    "    label='95% CI'\n",
    ")\n",
    "axes[0].set_title('Exact GP (RBF): First 1000 Test Points', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Time step')\n",
    "axes[0].set_ylabel('IOPS Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "residuals_rbf = y_test[:n_viz] - mean_exact_rbf[:n_viz]\n",
    "axes[1].scatter(np.arange(n_viz), residuals_rbf, alpha=0.3, s=10, color='red')\n",
    "axes[1].axhline(y=0, color='k', linestyle='--', linewidth=2)\n",
    "axes[1].set_title('Residuals', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Time step')\n",
    "axes[1].set_ylabel('Residual (Actual - Predicted)')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6855540",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Sparse Variational GP Approach (Original - For Comparison)\n",
    "\n",
    "### **Approach Comparison**\n",
    "\n",
    "| Aspect | **Robust (Recommended)** | **Traditional (Baseline)** |\n",
    "|--------|-------------------------|---------------------------|\n",
    "| **Training Data** | ALL 146,255 samples | 145,970 samples (exclude anomalies) |\n",
    "| **Likelihood** | Student-t (ν=4) | Gaussian |\n",
    "| **Philosophy** | Outliers are real data | Outliers corrupt training |\n",
    "| **Robustness** | Heavy tails handle extremes | Assumes normality |\n",
    "| **Production** | Trained on operational reality | Trained on sanitized data |\n",
    "\n",
    "### **Why Student-t Likelihood?**\n",
    "\n",
    "The Student-t distribution has **heavy tails** controlled by degrees of freedom (ν):\n",
    "\n",
    "$$\n",
    "p(y | \\mu, \\sigma, \\nu) = \\frac{\\Gamma(\\frac{\\nu+1}{2})}{\\Gamma(\\frac{\\nu}{2})\\sqrt{\\pi\\nu}\\sigma} \\left(1 + \\frac{1}{\\nu}\\left(\\frac{y-\\mu}{\\sigma}\\right)^2\\right)^{-\\frac{\\nu+1}{2}}\n",
    "$$\n",
    "\n",
    "- **ν=4:** Good balance between robustness and efficiency\n",
    "- **Lower ν** → Heavier tails → More robust to outliers\n",
    "- **As ν→∞** → Converges to Gaussian\n",
    "\n",
    "**Key advantage:** Outliers contribute less to parameter learning, allowing the model to learn patterns despite occasional anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Using the Gaussian Process Library\n",
    "\n",
    "**NOTE:** The implementation details (kernel design, model architecture, training loops) have been extracted to the `cloud_sim.ml_models.gaussian_process` library for production use.\n",
    "\n",
    "**For design rationale and implementation details, see:** `docs/modeling/gaussian-process-design.md`\n",
    "\n",
    "### **5.1 Library Architecture Overview**\n",
    "\n",
    "The GP module provides:\n",
    "\n",
    "1. **`CompositePeriodicKernel`**: Multi-scale periodic kernel\n",
    "   - SLOW component: Sawtooth envelope (1250 steps ≈ 21 hours)\n",
    "   - FAST component: Sinusoidal carrier (250 steps ≈ 4 hours)\n",
    "   - ADDITIVE structure for numerical stability\n",
    "\n",
    "2. **`SparseGPModel`**: Variational sparse GP with O(nm²) complexity\n",
    "   - Uses inducing points for scalability\n",
    "   - Learns inducing locations during training\n",
    "   - Cholesky variational distribution\n",
    "\n",
    "3. **Training utilities**: `train_gp_model`, `save_model`, `load_model`\n",
    "   - Mini-batch training with ELBO objective\n",
    "   - Maximum numerical stability settings\n",
    "   - Progress tracking and model persistence\n",
    "\n",
    "4. **Evaluation metrics**: `compute_metrics`, `compute_anomaly_metrics`\n",
    "   - Point accuracy (RMSE, MAE, R²)\n",
    "   - Uncertainty calibration (coverage, sharpness)\n",
    "   - Anomaly detection (precision, recall, F1, AUC-ROC)\n",
    "\n",
    "### **5.2 Initialize Models Using Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize inducing points (evenly spaced across training data)\n",
    "M = 200  # Number of inducing points\n",
    "\n",
    "inducing_points = initialize_inducing_points(\n",
    "    X_train=X_train_t,\n",
    "    num_inducing=M,\n",
    "    method=\"evenly_spaced\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Inducing points initialized:\")\n",
    "print(f\"  Count: {M}\")\n",
    "print(f\"  Shape: {inducing_points.shape}\")\n",
    "print(f\"  Range: {inducing_points.min():.6f} → {inducing_points.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce01f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training data statistics for proper initialization\n",
    "y_train_mean = y_train.mean()\n",
    "y_train_std = y_train.std()\n",
    "y_train_var = y_train.var()\n",
    "\n",
    "print(f\"Training data statistics:\")\n",
    "print(f\"  Mean: {y_train_mean:.3f}\")\n",
    "print(f\"  Std: {y_train_std:.3f}\")\n",
    "print(f\"  Variance: {y_train_var:.3f}\")\n",
    "print()\n",
    "print(\"⚠️  CRITICAL: Proper initialization required for variational GP!\")\n",
    "print(\"   Default initialization (mean=0, outputscale=1) causes scale mismatch\")\n",
    "print(\"   with variational inference's KL penalty, leading to underfitting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96302f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create robust model with Student-t likelihood\n",
    "model_robust = SparseGPModel(\n",
    "    inducing_points=inducing_points,\n",
    "    slow_period=1250 / X_range,  # Sawtooth envelope period\n",
    "    fast_period=250 / X_range,   # Sinusoidal carrier period\n",
    "    rbf_lengthscale=0.1\n",
    ").to(device)\n",
    "\n",
    "likelihood_robust = StudentTLikelihood(\n",
    "    deg_free_prior=gpytorch.priors.NormalPrior(4.0, 1.0)\n",
    ").to(device)\n",
    "\n",
    "# Initialize mean function to training data mean\n",
    "model_robust.mean_module.constant.data.fill_(y_train_mean)\n",
    "\n",
    "# Initialize kernel outputscales based on data variance\n",
    "# Distribute variance across the three kernel components\n",
    "variance_per_component = y_train_var / 3.0\n",
    "initial_outputscale = variance_per_component\n",
    "\n",
    "model_robust.covar_module.slow_periodic.outputscale = initial_outputscale\n",
    "model_robust.covar_module.fast_periodic.outputscale = initial_outputscale\n",
    "model_robust.covar_module.rbf.outputscale = initial_outputscale\n",
    "\n",
    "print(\"✓ Robust model initialized (Student-t likelihood)\")\n",
    "print(f\"  Training on ALL {len(X_train_t):,} samples (including anomalies)\")\n",
    "print(f\"  Mean initialized to: {model_robust.mean_module.constant.item():.3f}\")\n",
    "print(f\"  Outputscales initialized to: {initial_outputscale:.3f} each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute clean training data statistics for proper initialization\n",
    "y_train_clean_mean = y_train_clean.mean()\n",
    "y_train_clean_var = y_train_clean.var()\n",
    "\n",
    "print(f\"Clean training data statistics:\")\n",
    "print(f\"  Mean: {y_train_clean_mean:.3f}\")\n",
    "print(f\"  Variance: {y_train_clean_var:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traditional model with Gaussian likelihood (baseline)\n",
    "inducing_points_clean = initialize_inducing_points(\n",
    "    X_train=X_train_clean_t,\n",
    "    num_inducing=M,\n",
    "    method=\"evenly_spaced\"\n",
    ")\n",
    "\n",
    "model_traditional = SparseGPModel(\n",
    "    inducing_points=inducing_points_clean,\n",
    "    slow_period=1250 / X_range,\n",
    "    fast_period=250 / X_range,\n",
    "    rbf_lengthscale=0.1\n",
    ").to(device)\n",
    "\n",
    "likelihood_traditional = GaussianLikelihood().to(device)\n",
    "\n",
    "# Initialize mean function to clean training data mean\n",
    "model_traditional.mean_module.constant.data.fill_(y_train_clean_mean)\n",
    "\n",
    "# Initialize kernel outputscales based on clean data variance\n",
    "variance_per_component_clean = y_train_clean_var / 3.0\n",
    "model_traditional.covar_module.slow_periodic.outputscale = variance_per_component_clean\n",
    "model_traditional.covar_module.fast_periodic.outputscale = variance_per_component_clean\n",
    "model_traditional.covar_module.rbf.outputscale = variance_per_component_clean\n",
    "\n",
    "print(\"✓ Traditional model initialized (Gaussian likelihood)\")\n",
    "print(f\"  Training on {len(X_train_clean_t):,} samples (excluded {n_anomalies_train} anomalies)\")\n",
    "print(f\"  Mean initialized to: {model_traditional.mean_module.constant.item():.3f}\")\n",
    "print(f\"  Outputscales initialized to: {variance_per_component_clean:.3f} each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361501b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Model Training\n",
    "\n",
    "### 6.1 Check for Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if saved models exist\n",
    "robust_model_path = '../models/gp_robust_model.pth'\n",
    "traditional_model_path = '../models/gp_traditional_model.pth'\n",
    "\n",
    "models_exist = os.path.exists(robust_model_path) and os.path.exists(traditional_model_path)\n",
    "\n",
    "if models_exist:\n",
    "    print(\"✓ Found saved models - loading from disk...\")\n",
    "    print(f\"  Robust: {robust_model_path}\")\n",
    "    print(f\"  Traditional: {traditional_model_path}\")\n",
    "    print(\"\\nTo retrain from scratch, delete the models/ directory\")\n",
    "else:\n",
    "    print(\"✗ No saved models found - will train from scratch\")\n",
    "    print(\"\\nModels will be saved to ../models/ after training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76e574",
   "metadata": {},
   "source": [
    "### 6.2 Train or Load Robust Model (Student-t Likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f70aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if it exists, otherwise train from scratch\n",
    "if models_exist:\n",
    "    model_robust, likelihood_robust, checkpoint_robust = load_model(\n",
    "        load_path=robust_model_path,\n",
    "        likelihood_class=StudentTLikelihood,\n",
    "        device=device,\n",
    "        # Kernel parameters for backward compatibility with old checkpoints\n",
    "        slow_period=1250 / X_range,\n",
    "        fast_period=250 / X_range,\n",
    "        rbf_lengthscale=0.1\n",
    "    )\n",
    "    losses_robust = checkpoint_robust['losses']\n",
    "else:\n",
    "    # Train robust model using library (with device-specific jitter)\n",
    "    losses_robust = train_gp_model(\n",
    "        model=model_robust,\n",
    "        likelihood=likelihood_robust,\n",
    "        X_train=X_train_t,\n",
    "        y_train=y_train_t,\n",
    "        n_epochs=100,\n",
    "        batch_size=2048,\n",
    "        learning_rate=0.01,\n",
    "        cholesky_jitter=cholesky_jitter,\n",
    "        cholesky_max_tries=cholesky_max_tries,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Save trained model\n",
    "    save_model(\n",
    "        model=model_robust,\n",
    "        likelihood=likelihood_robust,\n",
    "        save_path=robust_model_path,\n",
    "        losses=losses_robust,\n",
    "        metadata={'dataset': 'IOPS', 'approach': 'robust'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591e0b8",
   "metadata": {},
   "source": [
    "### 6.3 Train or Load Traditional Model (Gaussian Likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if it exists, otherwise train from scratch\n",
    "if models_exist:\n",
    "    model_traditional, likelihood_traditional, checkpoint_trad = load_model(\n",
    "        load_path=traditional_model_path,\n",
    "        likelihood_class=GaussianLikelihood,\n",
    "        device=device,\n",
    "        # Kernel parameters for backward compatibility with old checkpoints\n",
    "        slow_period=1250 / X_range,\n",
    "        fast_period=250 / X_range,\n",
    "        rbf_lengthscale=0.1\n",
    "    )\n",
    "    losses_traditional = checkpoint_trad['losses']\n",
    "else:\n",
    "    # Train traditional model using library (with device-specific jitter)\n",
    "    losses_traditional = train_gp_model(\n",
    "        model=model_traditional,\n",
    "        likelihood=likelihood_traditional,\n",
    "        X_train=X_train_clean_t,\n",
    "        y_train=y_train_clean_t,\n",
    "        n_epochs=100,\n",
    "        batch_size=2048,\n",
    "        learning_rate=0.01,\n",
    "        cholesky_jitter=cholesky_jitter,\n",
    "        cholesky_max_tries=cholesky_max_tries,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Save trained model\n",
    "    save_model(\n",
    "        model=model_traditional,\n",
    "        likelihood=likelihood_traditional,\n",
    "        save_path=traditional_model_path,\n",
    "        losses=losses_traditional,\n",
    "        metadata={'dataset': 'IOPS', 'approach': 'traditional'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0475180",
   "metadata": {},
   "source": [
    "### 6.4 Training Loss Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87965ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training losses\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.plot(losses_robust, linewidth=2, label='Robust (Student-t, all data)', color='steelblue')\n",
    "ax.plot(losses_traditional, linewidth=2, label='Traditional (Gaussian, clean data)', color='coral')\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Negative ELBO Loss', fontsize=12)\n",
    "ax.set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556cfcb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Prediction and Uncertainty Quantification\n",
    "\n",
    "### 8.1 Robust Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "model_robust.eval()\n",
    "likelihood_robust.eval()\n",
    "\n",
    "print(\"Generating predictions with robust model...\")\n",
    "print(f\"Test samples: {len(X_test_t):,}\")\n",
    "\n",
    "# Batched prediction to prevent memory exhaustion\n",
    "batch_size_pred = 4096  # Process in chunks\n",
    "n_batches = int(np.ceil(len(X_test_t) / batch_size_pred))\n",
    "\n",
    "mean_robust_list = []\n",
    "std_robust_list = []\n",
    "\n",
    "# Apply same numerical stability settings as training (device-specific)\n",
    "with torch.no_grad(), \\\n",
    "     gpytorch.settings.fast_pred_var(), \\\n",
    "     gpytorch.settings.cholesky_jitter(cholesky_jitter), \\\n",
    "     gpytorch.settings.cholesky_max_tries(cholesky_max_tries):\n",
    "\n",
    "    for batch_idx in range(n_batches):\n",
    "        start_idx = batch_idx * batch_size_pred\n",
    "        end_idx = min(start_idx + batch_size_pred, len(X_test_t))\n",
    "\n",
    "        X_batch = X_test_t[start_idx:end_idx]\n",
    "\n",
    "        # Get predictive distribution for batch\n",
    "        pred_dist_batch = likelihood_robust(model_robust(X_batch))\n",
    "\n",
    "        # Extract mean and variance (move to CPU, then to numpy)\n",
    "        mean_batch = pred_dist_batch.mean.cpu().numpy()\n",
    "        std_batch = pred_dist_batch.stddev.cpu().numpy()\n",
    "\n",
    "        # Flatten to 1D (handle any batch/feature dimensions)\n",
    "        mean_batch = mean_batch.flatten()\n",
    "        std_batch = std_batch.flatten()\n",
    "\n",
    "        # Sanity check: should match batch size\n",
    "        expected_size = end_idx - start_idx\n",
    "        if mean_batch.size != expected_size:\n",
    "            print(f\"  WARNING: Batch {batch_idx} size mismatch: got {mean_batch.size}, expected {expected_size}\")\n",
    "            # Truncate or pad to expected size\n",
    "            mean_batch = mean_batch[:expected_size]\n",
    "            std_batch = std_batch[:expected_size]\n",
    "\n",
    "        mean_robust_list.append(mean_batch)\n",
    "        std_robust_list.append(std_batch)\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == n_batches:\n",
    "            print(f\"  Processed {end_idx:,}/{len(X_test_t):,} samples ({100*end_idx/len(X_test_t):.1f}%)\")\n",
    "\n",
    "# Concatenate all batches\n",
    "mean_robust = np.concatenate(mean_robust_list)\n",
    "std_robust = np.concatenate(std_robust_list)\n",
    "\n",
    "print(f\"✓ Predictions generated\")\n",
    "print(f\"  Mean range: {mean_robust.min():.2f} → {mean_robust.max():.2f}\")\n",
    "print(f\"  Std range: {std_robust.min():.2f} → {std_robust.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction intervals using library function\n",
    "nu_final = likelihood_robust.deg_free.item()\n",
    "\n",
    "intervals_robust = compute_prediction_intervals(\n",
    "    mean=mean_robust,\n",
    "    std=std_robust,\n",
    "    confidence_levels=[0.95, 0.99],\n",
    "    distribution=\"student_t\",\n",
    "    nu=nu_final\n",
    ")\n",
    "\n",
    "lower_95_robust, upper_95_robust = intervals_robust[0.95]\n",
    "lower_99_robust, upper_99_robust = intervals_robust[0.99]\n",
    "\n",
    "# Display quantiles for reference\n",
    "q_95 = student_t.ppf(0.975, df=nu_final)\n",
    "q_99 = student_t.ppf(0.995, df=nu_final)\n",
    "\n",
    "print(f\"✓ Prediction intervals computed (Student-t, ν={nu_final:.2f}):\")\n",
    "print(f\"  95% quantile: ±{q_95:.3f}\")\n",
    "print(f\"  99% quantile: ±{q_99:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84503c7b",
   "metadata": {},
   "source": [
    "### 8.2 Traditional Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "model_traditional.eval()\n",
    "likelihood_traditional.eval()\n",
    "\n",
    "print(\"Generating predictions with traditional model...\")\n",
    "print(f\"Test samples: {len(X_test_t):,}\")\n",
    "\n",
    "# Batched prediction to prevent memory exhaustion\n",
    "mean_traditional_list = []\n",
    "std_traditional_list = []\n",
    "\n",
    "# Apply same numerical stability settings as training (device-specific)\n",
    "with torch.no_grad(), \\\n",
    "     gpytorch.settings.fast_pred_var(), \\\n",
    "     gpytorch.settings.cholesky_jitter(cholesky_jitter), \\\n",
    "     gpytorch.settings.cholesky_max_tries(cholesky_max_tries):\n",
    "\n",
    "    for batch_idx in range(n_batches):\n",
    "        start_idx = batch_idx * batch_size_pred\n",
    "        end_idx = min(start_idx + batch_size_pred, len(X_test_t))\n",
    "\n",
    "        X_batch = X_test_t[start_idx:end_idx]\n",
    "\n",
    "        # Get predictive distribution for batch\n",
    "        pred_dist_batch = likelihood_traditional(model_traditional(X_batch))\n",
    "\n",
    "        # Extract mean and variance (move to CPU, then to numpy)\n",
    "        mean_batch = pred_dist_batch.mean.cpu().numpy()\n",
    "        std_batch = pred_dist_batch.stddev.cpu().numpy()\n",
    "\n",
    "        # Flatten to 1D (handle any batch/feature dimensions)\n",
    "        mean_batch = mean_batch.flatten()\n",
    "        std_batch = std_batch.flatten()\n",
    "\n",
    "        # Sanity check: should match batch size\n",
    "        expected_size = end_idx - start_idx\n",
    "        if mean_batch.size != expected_size:\n",
    "            print(f\"  WARNING: Batch {batch_idx} size mismatch: got {mean_batch.size}, expected {expected_size}\")\n",
    "            # Truncate to expected size\n",
    "            mean_batch = mean_batch[:expected_size]\n",
    "            std_batch = std_batch[:expected_size]\n",
    "\n",
    "        mean_traditional_list.append(mean_batch)\n",
    "        std_traditional_list.append(std_batch)\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == n_batches:\n",
    "            print(f\"  Processed {end_idx:,}/{len(X_test_t):,} samples ({100*end_idx/len(X_test_t):.1f}%)\")\n",
    "\n",
    "# Concatenate all batches\n",
    "mean_traditional = np.concatenate(mean_traditional_list)\n",
    "std_traditional = np.concatenate(std_traditional_list)\n",
    "\n",
    "print(f\"✓ Predictions generated\")\n",
    "print(f\"  Mean range: {mean_traditional.min():.2f} → {mean_traditional.max():.2f}\")\n",
    "print(f\"  Std range: {std_traditional.min():.2f} → {std_traditional.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0291ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute prediction intervals using library function\n",
    "intervals_traditional = compute_prediction_intervals(\n",
    "    mean=mean_traditional,\n",
    "    std=std_traditional,\n",
    "    confidence_levels=[0.95, 0.99],\n",
    "    distribution=\"gaussian\"\n",
    ")\n",
    "\n",
    "lower_95_traditional, upper_95_traditional = intervals_traditional[0.95]\n",
    "lower_99_traditional, upper_99_traditional = intervals_traditional[0.99]\n",
    "\n",
    "# Display quantiles for reference\n",
    "q_95_gauss = norm.ppf(0.975)\n",
    "q_99_gauss = norm.ppf(0.995)\n",
    "\n",
    "print(f\"✓ Prediction intervals computed (Gaussian):\")\n",
    "print(f\"  95% quantile: ±{q_95_gauss:.3f}\")\n",
    "print(f\"  99% quantile: ±{q_99_gauss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3735a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Model Evaluation\n",
    "\n",
    "### 9.1 Prediction Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd8c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics using library function\n",
    "metrics_robust = compute_metrics(\n",
    "    y_true=y_test,\n",
    "    y_pred=mean_robust,\n",
    "    lower_95=lower_95_robust,\n",
    "    upper_95=upper_95_robust,\n",
    "    lower_99=lower_99_robust,\n",
    "    upper_99=upper_99_robust,\n",
    "    model_name='Robust (Student-t)'\n",
    ")\n",
    "\n",
    "metrics_traditional = compute_metrics(\n",
    "    y_true=y_test,\n",
    "    y_pred=mean_traditional,\n",
    "    lower_95=lower_95_traditional,\n",
    "    upper_95=upper_95_traditional,\n",
    "    lower_99=lower_99_traditional,\n",
    "    upper_99=upper_99_traditional,\n",
    "    model_name='Traditional (Gaussian)'\n",
    ")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "metrics_df = spark.createDataFrame([metrics_robust, metrics_traditional])\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for metric_name in ['RMSE', 'MAE', 'R²', 'Coverage 95%', 'Coverage 99%', 'Sharpness 95%', 'Sharpness 99%']:\n",
    "    robust_val = metrics_robust[metric_name]\n",
    "    trad_val = metrics_traditional[metric_name]\n",
    "\n",
    "    # Format based on metric type\n",
    "    if 'Coverage' in metric_name:\n",
    "        print(f\"{metric_name:20s} | Robust: {robust_val:6.1%} | Traditional: {trad_val:6.1%}\")\n",
    "    else:\n",
    "        print(f\"{metric_name:20s} | Robust: {robust_val:6.3f} | Traditional: {trad_val:6.3f}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245c795",
   "metadata": {},
   "source": [
    "### 9.2 Detailed Diagnostic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405032d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive diagnostics to understand model behavior\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from diagnose_gp_results import diagnose_gp_predictions\n",
    "\n",
    "# Generate diagnostic report\n",
    "diagnose_gp_predictions(\n",
    "    y_test=y_test,\n",
    "    mean_robust=mean_robust,\n",
    "    mean_traditional=mean_traditional,\n",
    "    model_robust=model_robust,\n",
    "    model_traditional=model_traditional,\n",
    "    X_test_t=X_test_t,\n",
    "    save_path=\"../gp_diagnostics.txt\"\n",
    ")\n",
    "\n",
    "# Display the report\n",
    "with open(\"../gp_diagnostics.txt\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c80621d",
   "metadata": {},
   "source": [
    "### 9.3 Calibration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b993c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute standardized residuals\n",
    "residuals_robust = (y_test - mean_robust) / std_robust\n",
    "residuals_traditional = (y_test - mean_traditional) / std_traditional\n",
    "\n",
    "# Expected vs observed quantiles (Q-Q plot)\n",
    "quantiles = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "# For robust model, compare against Student-t\n",
    "expected_quantiles_robust = student_t.ppf(quantiles, df=nu_final)\n",
    "observed_quantiles_robust = np.quantile(residuals_robust, quantiles)\n",
    "\n",
    "# For traditional model, compare against Gaussian\n",
    "expected_quantiles_trad = norm.ppf(quantiles)\n",
    "observed_quantiles_trad = np.quantile(residuals_traditional, quantiles)\n",
    "\n",
    "# Plot calibration\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Robust model calibration\n",
    "axes[0].scatter(expected_quantiles_robust, observed_quantiles_robust, alpha=0.6, s=30, color='steelblue')\n",
    "axes[0].plot([-4, 4], [-4, 4], 'r--', linewidth=2, label='Perfect Calibration')\n",
    "axes[0].set_xlabel(f'Expected Quantiles (Student-t, ν={nu_final:.2f})', fontsize=12)\n",
    "axes[0].set_ylabel('Observed Quantiles (Standardized Residuals)', fontsize=12)\n",
    "axes[0].set_title('Robust Model Calibration', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Traditional model calibration\n",
    "axes[1].scatter(expected_quantiles_trad, observed_quantiles_trad, alpha=0.6, s=30, color='coral')\n",
    "axes[1].plot([-4, 4], [-4, 4], 'r--', linewidth=2, label='Perfect Calibration')\n",
    "axes[1].set_xlabel('Expected Quantiles (Gaussian)', fontsize=12)\n",
    "axes[1].set_ylabel('Observed Quantiles (Standardized Residuals)', fontsize=12)\n",
    "axes[1].set_title('Traditional Model Calibration', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7203e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Anomaly Detection\n",
    "\n",
    "### 10.1 Detection via Prediction Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66debada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag anomalies using prediction intervals\n",
    "anomalies_95_robust = (y_test < lower_95_robust) | (y_test > upper_95_robust)\n",
    "anomalies_99_robust = (y_test < lower_99_robust) | (y_test > upper_99_robust)\n",
    "\n",
    "anomalies_95_traditional = (y_test < lower_95_traditional) | (y_test > upper_95_traditional)\n",
    "anomalies_99_traditional = (y_test < lower_99_traditional) | (y_test > upper_99_traditional)\n",
    "\n",
    "print(f\"Anomalies detected:\")\n",
    "print(f\"  Robust (95%): {anomalies_95_robust.sum():,}\")\n",
    "print(f\"  Robust (99%): {anomalies_99_robust.sum():,}\")\n",
    "print(f\"  Traditional (95%): {anomalies_95_traditional.sum():,}\")\n",
    "print(f\"  Traditional (99%): {anomalies_99_traditional.sum():,}\")\n",
    "print(f\"  Ground truth: {anomaly_test.sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebbdd7",
   "metadata": {},
   "source": [
    "### 10.2 Anomaly Detection Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bd187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute anomaly detection metrics using library function\n",
    "anomaly_metrics = [\n",
    "    compute_anomaly_metrics(\n",
    "        y_true_anomaly=anomaly_test,\n",
    "        y_pred_anomaly=anomalies_95_robust,\n",
    "        model_name='Robust (Student-t)',\n",
    "        threshold_name='95% Interval'\n",
    "    ),\n",
    "    compute_anomaly_metrics(\n",
    "        y_true_anomaly=anomaly_test,\n",
    "        y_pred_anomaly=anomalies_99_robust,\n",
    "        model_name='Robust (Student-t)',\n",
    "        threshold_name='99% Interval'\n",
    "    ),\n",
    "    compute_anomaly_metrics(\n",
    "        y_true_anomaly=anomaly_test,\n",
    "        y_pred_anomaly=anomalies_95_traditional,\n",
    "        model_name='Traditional (Gaussian)',\n",
    "        threshold_name='95% Interval'\n",
    "    ),\n",
    "    compute_anomaly_metrics(\n",
    "        y_true_anomaly=anomaly_test,\n",
    "        y_pred_anomaly=anomalies_99_traditional,\n",
    "        model_name='Traditional (Gaussian)',\n",
    "        threshold_name='99% Interval'\n",
    "    ),\n",
    "]\n",
    "\n",
    "anomaly_metrics_df = spark.createDataFrame(anomaly_metrics)\n",
    "anomaly_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71feb9d8",
   "metadata": {},
   "source": [
    "### 10.3 ROC Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute anomaly scores (standardized residuals)\n",
    "anomaly_scores_robust = np.abs((y_test - mean_robust) / std_robust)\n",
    "anomaly_scores_traditional = np.abs((y_test - mean_traditional) / std_traditional)\n",
    "\n",
    "# Compute ROC curves\n",
    "fpr_robust, tpr_robust, thresholds_robust = roc_curve(anomaly_test, anomaly_scores_robust)\n",
    "fpr_traditional, tpr_traditional, thresholds_traditional = roc_curve(anomaly_test, anomaly_scores_traditional)\n",
    "\n",
    "# Compute AUC-ROC\n",
    "auc_robust = roc_auc_score(anomaly_test, anomaly_scores_robust)\n",
    "auc_traditional = roc_auc_score(anomaly_test, anomaly_scores_traditional)\n",
    "\n",
    "print(f\"AUC-ROC Scores:\")\n",
    "print(f\"  Robust: {auc_robust:.4f}\")\n",
    "print(f\"  Traditional: {auc_traditional:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.plot(fpr_robust, tpr_robust, linewidth=2.5,\n",
    "        label=f'Robust (Student-t) - AUC = {auc_robust:.3f}', color='steelblue')\n",
    "ax.plot(fpr_traditional, tpr_traditional, linewidth=2.5,\n",
    "        label=f'Traditional (Gaussian) - AUC = {auc_traditional:.3f}', color='coral')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random Classifier', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=13)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=13)\n",
    "ax.set_title('ROC Curve: Anomaly Detection Performance', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=12, loc='lower right')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb2cea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Visualizations\n",
    "\n",
    "### 11.1 Prediction Plot with Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot subset for clarity (first 5000 test points)\n",
    "plot_start = 0\n",
    "plot_end = 5000\n",
    "\n",
    "X_plot = X_test[plot_start:plot_end].ravel()\n",
    "y_plot = y_test[plot_start:plot_end]\n",
    "mean_plot = mean_robust[plot_start:plot_end]\n",
    "lower_95_plot = lower_95_robust[plot_start:plot_end]\n",
    "upper_95_plot = upper_95_robust[plot_start:plot_end]\n",
    "anomaly_plot = anomaly_test[plot_start:plot_end]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "\n",
    "# Observations\n",
    "ax.plot(X_plot, y_plot, 'k.', alpha=0.3, markersize=2, label='Observed', zorder=1)\n",
    "\n",
    "# GP mean\n",
    "ax.plot(X_plot, mean_plot, 'b-', linewidth=2, label='GP Mean (Robust)', zorder=3)\n",
    "\n",
    "# 95% prediction interval\n",
    "ax.fill_between(\n",
    "    X_plot,\n",
    "    lower_95_plot,\n",
    "    upper_95_plot,\n",
    "    alpha=0.25,\n",
    "    color='steelblue',\n",
    "    label='95% Prediction Interval',\n",
    "    zorder=2\n",
    ")\n",
    "\n",
    "# Highlight labeled anomalies\n",
    "anomaly_mask = anomaly_plot.astype(bool)\n",
    "ax.scatter(\n",
    "    X_plot[anomaly_mask],\n",
    "    y_plot[anomaly_mask],\n",
    "    color='red',\n",
    "    s=60,\n",
    "    marker='x',\n",
    "    linewidths=2.5,\n",
    "    label=f'Labeled Anomalies ({anomaly_mask.sum()})',\n",
    "    zorder=4\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Timestamp', fontsize=12)\n",
    "ax.set_ylabel('KPI Value (IOPS)', fontsize=12)\n",
    "ax.set_title('Robust GP: Predictions with Uncertainty Quantification', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a222e00",
   "metadata": {},
   "source": [
    "### 11.2 Pattern Reconstruction: Sawtooth × Sinusoidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into one complete sawtooth cycle (~1250 normalized steps)\n",
    "cycle_length_norm = 1250 / X_range\n",
    "start_idx = 1000\n",
    "end_idx = start_idx + int(cycle_length_norm * len(X_test))\n",
    "\n",
    "# Ensure we don't exceed bounds\n",
    "end_idx = min(end_idx, len(X_test))\n",
    "\n",
    "X_cycle = X_test[start_idx:end_idx].ravel()\n",
    "y_cycle = y_test[start_idx:end_idx]\n",
    "mean_cycle = mean_robust[start_idx:end_idx]\n",
    "lower_cycle = lower_95_robust[start_idx:end_idx]\n",
    "upper_cycle = upper_95_robust[start_idx:end_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "\n",
    "# Observations\n",
    "ax.plot(X_cycle, y_cycle, 'k.', alpha=0.4, markersize=3, label='Observed')\n",
    "\n",
    "# GP mean (should capture sawtooth × sine)\n",
    "ax.plot(X_cycle, mean_cycle, 'b-', linewidth=2.5, label='GP Mean (captures pattern)')\n",
    "\n",
    "# Prediction interval\n",
    "ax.fill_between(X_cycle, lower_cycle, upper_cycle, alpha=0.25, color='steelblue', label='95% Interval')\n",
    "\n",
    "# Annotate the 5 sinusoidal oscillations\n",
    "if len(X_cycle) > 0:\n",
    "    cycle_width = (X_cycle[-1] - X_cycle[0]) / 5\n",
    "    for i in range(5):\n",
    "        segment_start = X_cycle[0] + i * cycle_width\n",
    "        segment_end = segment_start + cycle_width\n",
    "\n",
    "        ax.axvspan(segment_start, segment_end, alpha=0.08,\n",
    "                   color=['orange', 'green', 'blue', 'purple', 'red'][i])\n",
    "\n",
    "ax.set_xlabel('Timestamp', fontsize=12)\n",
    "ax.set_ylabel('KPI Value (IOPS)', fontsize=12)\n",
    "ax.set_title('Pattern Reconstruction: Sawtooth Envelope × 5 Sinusoidal Oscillations',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left', fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a1f2b",
   "metadata": {},
   "source": [
    "### 11.3 Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plots for both models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Robust model residuals\n",
    "axes[0, 0].scatter(mean_robust, residuals_robust, alpha=0.3, s=10, color='steelblue')\n",
    "axes[0, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Predicted Value', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Standardized Residuals', fontsize=11)\n",
    "axes[0, 0].set_title('Robust: Residuals vs Predicted', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[0, 1].hist(residuals_robust, bins=100, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Standardized Residuals', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0, 1].set_title('Robust: Residual Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Traditional model residuals\n",
    "axes[1, 0].scatter(mean_traditional, residuals_traditional, alpha=0.3, s=10, color='coral')\n",
    "axes[1, 0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Predicted Value', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Standardized Residuals', fontsize=11)\n",
    "axes[1, 0].set_title('Traditional: Residuals vs Predicted', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 1].hist(residuals_traditional, bins=100, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1, 1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Standardized Residuals', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 1].set_title('Traditional: Residual Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32b7f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef36640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table\n",
    "comparison_data = {\n",
    "    'Metric': [\n",
    "        'Training Samples',\n",
    "        'Likelihood',\n",
    "        'Degrees of Freedom (ν)',\n",
    "        '---',\n",
    "        'RMSE',\n",
    "        'MAE',\n",
    "        'R²',\n",
    "        '---',\n",
    "        '95% Coverage',\n",
    "        '99% Coverage',\n",
    "        '95% Sharpness',\n",
    "        '99% Sharpness',\n",
    "        '---',\n",
    "        'Precision (95% interval)',\n",
    "        'Recall (95% interval)',\n",
    "        'F1-Score (95% interval)',\n",
    "        'AUC-ROC',\n",
    "    ],\n",
    "    'Robust (Student-t)': [\n",
    "        f\"{len(X_train_t):,} (all data)\",\n",
    "        'Student-t',\n",
    "        f'{nu_final:.2f}',\n",
    "        '---',\n",
    "        f'{metrics_robust[\"RMSE\"]:.3f}',\n",
    "        f'{metrics_robust[\"MAE\"]:.3f}',\n",
    "        f'{metrics_robust[\"R²\"]:.3f}',\n",
    "        '---',\n",
    "        f'{metrics_robust[\"Coverage 95%\"]:.1%}',\n",
    "        f'{metrics_robust[\"Coverage 99%\"]:.1%}',\n",
    "        f'{metrics_robust[\"Sharpness 95%\"]:.3f}',\n",
    "        f'{metrics_robust[\"Sharpness 99%\"]:.3f}',\n",
    "        '---',\n",
    "        f'{anomaly_metrics[0][\"Precision\"]:.3f}',\n",
    "        f'{anomaly_metrics[0][\"Recall\"]:.3f}',\n",
    "        f'{anomaly_metrics[0][\"F1-Score\"]:.3f}',\n",
    "        f'{auc_robust:.3f}',\n",
    "    ],\n",
    "    'Traditional (Gaussian)': [\n",
    "        f\"{len(X_train_clean_t):,} (exclude anomalies)\",\n",
    "        'Gaussian',\n",
    "        '∞ (normal)',\n",
    "        '---',\n",
    "        f'{metrics_traditional[\"RMSE\"]:.3f}',\n",
    "        f'{metrics_traditional[\"MAE\"]:.3f}',\n",
    "        f'{metrics_traditional[\"R²\"]:.3f}',\n",
    "        '---',\n",
    "        f'{metrics_traditional[\"Coverage 95%\"]:.1%}',\n",
    "        f'{metrics_traditional[\"Coverage 99%\"]:.1%}',\n",
    "        f'{metrics_traditional[\"Sharpness 95%\"]:.3f}',\n",
    "        f'{metrics_traditional[\"Sharpness 99%\"]:.3f}',\n",
    "        '---',\n",
    "        f'{anomaly_metrics[2][\"Precision\"]:.3f}',\n",
    "        f'{anomaly_metrics[2][\"Recall\"]:.3f}',\n",
    "        f'{anomaly_metrics[2][\"F1-Score\"]:.3f}',\n",
    "        f'{auc_traditional:.3f}',\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = spark.createDataFrame(comparison_data)\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.toPandas().to_string(index=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f4bb0",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "**1. Pattern Reconstruction:**\n",
    "- ✅ Composite periodic kernel successfully captures sawtooth × sinusoidal pattern\n",
    "- ✅ Visual inspection confirms 5 oscillations per sawtooth cycle\n",
    "- ✅ GP mean tracks complex two-scale structure\n",
    "\n",
    "**2. Calibration Performance:**\n",
    "- ✅ **Robust model:** Better calibrated prediction intervals (closer to nominal 95%/99%)\n",
    "- ⚠ **Traditional model:** May under/overestimate uncertainty due to Gaussian assumption\n",
    "\n",
    "**3. Anomaly Detection:**\n",
    "- ✅ **Robust model:** Higher recall (catches more true anomalies)\n",
    "- ✅ **AUC-ROC:** Both models show strong discriminative ability\n",
    "- ⚠ **Trade-off:** Precision vs Recall depends on interval threshold (95% vs 99%)\n",
    "\n",
    "**4. Production Readiness:**\n",
    "- ✅ **Robust approach:** Trained on real operational data (all samples)\n",
    "- ✅ **Student-t likelihood:** Naturally handles outliers without pre-processing\n",
    "- ✅ **Sparse GP:** Scalable to large datasets (O(nm²) complexity)\n",
    "- ✅ **GPyTorch:** Production-proven library (Uber, Meta, Amazon)\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "**For Production Deployment:**\n",
    "1. **Use robust approach** (Student-t likelihood, train on all data)\n",
    "2. **Adaptive thresholding:** Tune 95%/99% intervals based on operational cost of false positives/negatives\n",
    "3. **Online learning:** Incrementally update model with new data\n",
    "4. **Ensemble methods:** Combine GP with other anomaly detectors for robustness\n",
    "\n",
    "**For Further Improvement:**\n",
    "5. **Add covariates:** Time-of-day, day-of-week features\n",
    "6. **Multi-output GP:** Model multiple related KPIs jointly\n",
    "7. **Spectral mixture kernel:** Automate period discovery\n",
    "8. **Deeper inducing points:** Increase M for higher accuracy (trade-off: computational cost)\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Deploy model via FastAPI endpoint\n",
    "- Integrate with monitoring dashboard\n",
    "- A/B test against existing anomaly detection system\n",
    "- Collect feedback from operations team\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- **GPyTorch:** [https://gpytorch.ai/](https://gpytorch.ai/)\n",
    "- **Sparse GPs (SVGP):** Hensman et al. (2013), \"Gaussian Processes for Big Data\"\n",
    "- **Student-t Processes:** Shah et al. (2014), \"Student-t Processes as Alternatives to Gaussian Processes\"\n",
    "- **Composite Kernels:** Rasmussen & Williams (2006), \"Gaussian Processes for Machine Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de9f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce1f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "ipython3",
   "formats": "notebooks//md:myst,notebooks/_build//ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
